{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "name": "BigData_Assignment_2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vET0Pgb9CmV2"
      },
      "source": [
        "# Assignment 2\n",
        "\n",
        "#### First Name: Blai\n",
        "#### Last Name: Ras\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ssdmbGw_CmV5"
      },
      "source": [
        "## 1. Load Data from JSON"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q2N9gYBZCr_z",
        "outputId": "55e10a60-d19f-4ddb-892e-1e47c9b8932c"
      },
      "source": [
        "!pip install pyspark"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pyspark\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/45/b0/9d6860891ab14a39d4bddf80ba26ce51c2f9dc4805e5c6978ac0472c120a/pyspark-3.1.1.tar.gz (212.3MB)\n",
            "\u001b[K     |████████████████████████████████| 212.3MB 68kB/s \n",
            "\u001b[?25hCollecting py4j==0.10.9\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/b6/6a4fb90cd235dc8e265a6a2067f2a2c99f0d91787f06aca4bcf7c23f3f80/py4j-0.10.9-py2.py3-none-any.whl (198kB)\n",
            "\u001b[K     |████████████████████████████████| 204kB 19.2MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.1.1-py2.py3-none-any.whl size=212767604 sha256=ea71d5c0bc146ea1650f80c463724d74610282a982f6b9f16c0306d81dbe6819\n",
            "  Stored in directory: /root/.cache/pip/wheels/0b/90/c0/01de724414ef122bd05f056541fb6a0ecf47c7ca655f8b3c0f\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.9 pyspark-3.1.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-05-13T09:19:58.802050Z",
          "start_time": "2021-05-13T09:19:58.009881Z"
        },
        "id": "kaO8nCoACmV6"
      },
      "source": [
        "\n",
        "from pyspark.sql import SparkSession \n",
        "spark = SparkSession.builder.appName(\"Twitter Analysis\")\\\n",
        ".getOrCreate()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SJpuKU75FXpa",
        "outputId": "ac76fa73-05bf-495e-93a9-3cb6b23304fc"
      },
      "source": [
        "!git clone https://github.com/rohit-nlp/BigDataCourseUB.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'BigDataCourseUB'...\n",
            "remote: Enumerating objects: 146, done.\u001b[K\n",
            "remote: Counting objects: 100% (45/45), done.\u001b[K\n",
            "remote: Compressing objects: 100% (36/36), done.\u001b[K\n",
            "remote: Total 146 (delta 10), reused 38 (delta 6), pack-reused 101\u001b[K\n",
            "Receiving objects: 100% (146/146), 104.52 MiB | 21.81 MiB/s, done.\n",
            "Resolving deltas: 100% (44/44), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XINKbagTCmV7"
      },
      "source": [
        "df_twitter = spark.read.json(\"BigDataCourseUB/assisgnment_2/corona_tweet_new.json\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vqk301daCmV8",
        "outputId": "8b1928c4-dbd2-40d0-ab25-55d7d952018c"
      },
      "source": [
        "df_twitter.printSchema()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- created_at: string (nullable = true)\n",
            " |-- favorite_count: long (nullable = true)\n",
            " |-- hashtags: array (nullable = true)\n",
            " |    |-- element: string (containsNull = true)\n",
            " |-- id: string (nullable = true)\n",
            " |-- in_reply_to_status_id: string (nullable = true)\n",
            " |-- in_reply_to_user_id_str: string (nullable = true)\n",
            " |-- location: string (nullable = true)\n",
            " |-- reply_count: long (nullable = true)\n",
            " |-- retweet_count: long (nullable = true)\n",
            " |-- source: string (nullable = true)\n",
            " |-- user: struct (nullable = true)\n",
            " |    |-- contributors_enabled: boolean (nullable = true)\n",
            " |    |-- created_at: string (nullable = true)\n",
            " |    |-- default_profile: boolean (nullable = true)\n",
            " |    |-- default_profile_image: boolean (nullable = true)\n",
            " |    |-- description: string (nullable = true)\n",
            " |    |-- favourites_count: long (nullable = true)\n",
            " |    |-- follow_request_sent: string (nullable = true)\n",
            " |    |-- followers_count: long (nullable = true)\n",
            " |    |-- following: string (nullable = true)\n",
            " |    |-- friends_count: long (nullable = true)\n",
            " |    |-- geo_enabled: boolean (nullable = true)\n",
            " |    |-- id: long (nullable = true)\n",
            " |    |-- id_str: string (nullable = true)\n",
            " |    |-- is_translator: boolean (nullable = true)\n",
            " |    |-- lang: string (nullable = true)\n",
            " |    |-- listed_count: long (nullable = true)\n",
            " |    |-- location: string (nullable = true)\n",
            " |    |-- name: string (nullable = true)\n",
            " |    |-- notifications: string (nullable = true)\n",
            " |    |-- profile_background_color: string (nullable = true)\n",
            " |    |-- profile_background_image_url: string (nullable = true)\n",
            " |    |-- profile_background_image_url_https: string (nullable = true)\n",
            " |    |-- profile_background_tile: boolean (nullable = true)\n",
            " |    |-- profile_banner_url: string (nullable = true)\n",
            " |    |-- profile_image_url: string (nullable = true)\n",
            " |    |-- profile_image_url_https: string (nullable = true)\n",
            " |    |-- profile_link_color: string (nullable = true)\n",
            " |    |-- profile_sidebar_border_color: string (nullable = true)\n",
            " |    |-- profile_sidebar_fill_color: string (nullable = true)\n",
            " |    |-- profile_text_color: string (nullable = true)\n",
            " |    |-- profile_use_background_image: boolean (nullable = true)\n",
            " |    |-- protected: boolean (nullable = true)\n",
            " |    |-- screen_name: string (nullable = true)\n",
            " |    |-- statuses_count: long (nullable = true)\n",
            " |    |-- time_zone: string (nullable = true)\n",
            " |    |-- translator_type: string (nullable = true)\n",
            " |    |-- url: string (nullable = true)\n",
            " |    |-- utc_offset: string (nullable = true)\n",
            " |    |-- verified: boolean (nullable = true)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gy5-RKHJCmV8"
      },
      "source": [
        "### From the user nestec col select the following cols only id_str,followers_count,friends_count and created at \n",
        "# (2 points)\n",
        "from pyspark.sql.functions import col, struct\n",
        "\n",
        "#Looking at the teacher's output below I see that the user columns have been renamed with \"user_*\" and that even though we are asked to take the user column \"friends_count\",\n",
        "#I cannot see it in the teacher's output. Nevertheless, I take it just in case. It also looks like we got rid of the column \"location\", but later on we need it.\n",
        "\n",
        "df_twitter = df_twitter.withColumn(\"user\", struct(\n",
        "                            col(\"user.id_str\").alias(\"user_id_str\"),\n",
        "                            col(\"user.followers_count\").alias(\"user_followers_count\"),\n",
        "                            col(\"user.friends_count\").alias(\"user_friends_count\"),\n",
        "                            col(\"user.created_at\").alias(\"user_created_at\")\n",
        "                            )).select([\"created_at\",\"favorite_count\",\"hashtags\",\"id\",\"in_reply_to_status_id\",\"in_reply_to_user_id_str\",\"location\",\"reply_count\",\"retweet_count\",\"source\",\n",
        "                                       \"user.user_id_str\",\"user.user_followers_count\",\"user.user_created_at\",\"user.user_friends_count\"])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rtPy3whdCmV8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4168391-82d0-4d39-dbf1-8554948288a7"
      },
      "source": [
        "df_twitter.printSchema()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- created_at: string (nullable = true)\n",
            " |-- favorite_count: long (nullable = true)\n",
            " |-- hashtags: array (nullable = true)\n",
            " |    |-- element: string (containsNull = true)\n",
            " |-- id: string (nullable = true)\n",
            " |-- in_reply_to_status_id: string (nullable = true)\n",
            " |-- in_reply_to_user_id_str: string (nullable = true)\n",
            " |-- location: string (nullable = true)\n",
            " |-- reply_count: long (nullable = true)\n",
            " |-- retweet_count: long (nullable = true)\n",
            " |-- source: string (nullable = true)\n",
            " |-- user_id_str: string (nullable = true)\n",
            " |-- user_followers_count: long (nullable = true)\n",
            " |-- user_created_at: string (nullable = true)\n",
            " |-- user_friends_count: long (nullable = true)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CR7UDW_7CmV9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb8f9ed8-df91-4742-c6e1-2f3abe89515b"
      },
      "source": [
        "# Print the total count of number of records in df_twitter(1 point)\n",
        "df_twitter.count()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "15894"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-wOehB0bCmV9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8efabfa3-e103-4fbf-fc56-63e285d1131f"
      },
      "source": [
        "# Extract the source lable from source col by droping the anchor tab and save it as another col named extracted_source\n",
        "# for example <a href=\"https://mobile.twitter.com\" rel=\"nofollow\">Twitter Web App</a> => Twitter Web App\n",
        "# you can use \"<a [^>]+>([^<]+)\" as regualr expresion and the group would be 1 for this regular expression.\n",
        "#(4 points)\n",
        "from pyspark.sql.functions import regexp_extract\n",
        "\n",
        "df_twitter=df_twitter.withColumn(\"extracted_source\",regexp_extract('source',r'<a [^>]+>([^<]+)',1))\n",
        "df_twitter.select(col('extracted_source'),col('source')).show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-------------------+--------------------+\n",
            "|   extracted_source|              source|\n",
            "+-------------------+--------------------+\n",
            "|    Twitter Web App|<a href=\"https://...|\n",
            "|Twitter for Android|<a href=\"http://t...|\n",
            "|Twitter for Android|<a href=\"http://t...|\n",
            "|Twitter for Android|<a href=\"http://t...|\n",
            "|Twitter for Android|<a href=\"http://t...|\n",
            "|    Twitter Web App|<a href=\"https://...|\n",
            "| Twitter Web Client|<a href=\"http://t...|\n",
            "|Twitter for Android|<a href=\"http://t...|\n",
            "|Twitter for Android|<a href=\"http://t...|\n",
            "| Twitter for iPhone|<a href=\"http://t...|\n",
            "| Twitter for iPhone|<a href=\"http://t...|\n",
            "|    Twitter Web App|<a href=\"https://...|\n",
            "|Twitter for Android|<a href=\"http://t...|\n",
            "|    Twitter Web App|<a href=\"https://...|\n",
            "| Twitter for iPhone|<a href=\"http://t...|\n",
            "|Twitter for Android|<a href=\"http://t...|\n",
            "| Twitter for iPhone|<a href=\"http://t...|\n",
            "|Twitter for Android|<a href=\"http://t...|\n",
            "| Twitter for iPhone|<a href=\"http://t...|\n",
            "|Twitter for Android|<a href=\"http://t...|\n",
            "+-------------------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y_gyQI_oCmV9"
      },
      "source": [
        "# Convert the DataFrame into RDD\n",
        "rdd_twitter=df_twitter.rdd.map(tuple)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XOtLzeU-CmV9"
      },
      "source": [
        "# Create a temporay table in memory with name as twitter (1 point)\n",
        "\n",
        "df_twitter.createTempView(\"twitter\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jmTlJ_zPCmV-"
      },
      "source": [
        "## 2. Analyze Data\n",
        "\n",
        "#### You will be writing code to find the answer to the questions listed below using Just RDD, Using spark SQL \n",
        "\n",
        "- Analyze using RDD \n",
        "- Analyze using Dataframe without temp table \n",
        "- Analyze using spark.sql with temp table\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MVUa0-1ICmV-"
      },
      "source": [
        "#### 2.1 Get total number of unique users (1 point for each type)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bXXiwL0HiyWS",
        "outputId": "2c9fa203-f34b-410a-b35d-bd052c381264"
      },
      "source": [
        "#This is so I can remember the index when using the rdd functions\n",
        "for i,j in enumerate(df_twitter.columns):\n",
        "    print(\"Column\",i,\":\",j)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Column 0 : created_at\n",
            "Column 1 : favorite_count\n",
            "Column 2 : hashtags\n",
            "Column 3 : id\n",
            "Column 4 : in_reply_to_status_id\n",
            "Column 5 : in_reply_to_user_id_str\n",
            "Column 6 : location\n",
            "Column 7 : reply_count\n",
            "Column 8 : retweet_count\n",
            "Column 9 : source\n",
            "Column 10 : user_id_str\n",
            "Column 11 : user_followers_count\n",
            "Column 12 : user_created_at\n",
            "Column 13 : user_friends_count\n",
            "Column 14 : extracted_source\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MrZ9ZW-3CmV-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d3ecff36-dabc-4f28-b56a-9db1fcfdc88e"
      },
      "source": [
        "# Using RDD\n",
        "#Use the count and distinct functions\n",
        "print(\"Total number of tweets:\", rdd_twitter.count(),\", from\",rdd_twitter.map(lambda x: x[10]).distinct().count(),\"unique users\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total number of tweets: 15894 , from 14094 unique users\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gh6WoZ50CmV-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50bf3098-7d56-41fe-9b62-a9e6edd5b636"
      },
      "source": [
        "# Using DataFrame\n",
        "print(\"Total number of tweets:\", df_twitter.count(),\", from\",df_twitter.select(\"user_id_str\").distinct().count(),\"unique users\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total number of tweets: 15894 , from 14094 unique users\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lSYatCaNCmV_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3088222f-707d-4aa8-e5c1-909aa930fcf4"
      },
      "source": [
        "# Using spark.sql and the temporay table.\n",
        "\n",
        "spark.sql('''\n",
        "    SELECT COUNT(DISTINCT user_id_str) AS Total_number_of_unique_users\n",
        "    FROM twitter''').show()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+----------------------------+\n",
            "|Total_number_of_unique_users|\n",
            "+----------------------------+\n",
            "|                       14094|\n",
            "+----------------------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o5RTY5xFCmV_"
      },
      "source": [
        "#### 2.2 Get count of user who have more than 1 tweet in the data (2 points)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AufoGjqUCmV_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fbd4b50b-909e-42ff-8f99-b6b1db24a9a3"
      },
      "source": [
        "# Using RDD\n",
        "\n",
        "#First get the unique users\n",
        "userCount = rdd_twitter.map(lambda x: x[10]).distinct()\n",
        "#And then countByValue\n",
        "mapping = rdd_twitter.map(lambda x: x[10]).countByValue()\n",
        "#So we can now filter and count the rows\n",
        "userCount.filter(lambda x: mapping[x]>1).count()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1016"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EzopfJ26CmV_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ca7e358-1946-4a29-a083-b9b55552d6f8"
      },
      "source": [
        "# Using DataFrame\n",
        "df_twitter.groupby(\"user_id_str\").count().filter(\"count > 1\").count()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1016"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-qSo1p2aCmV_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "627d38c5-7a8c-4c3e-ca52-2d51c9593109"
      },
      "source": [
        "# Using spark.sql and the temporay table.\n",
        "spark.sql('''\n",
        "    SELECT COUNT(*) AS Users_more_1_tweet FROM (\n",
        "        SELECT COUNT(user_id_str) FROM twitter\n",
        "        GROUP BY user_id_str \n",
        "        HAVING COUNT(user_id_str) > 1)''').show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+------------------+\n",
            "|Users_more_1_tweet|\n",
            "+------------------+\n",
            "|              1016|\n",
            "+------------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vcPGMej4CmWA"
      },
      "source": [
        "#### 2.3 Get total number unique extracted_source (1 point each)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xWc8FMyWCmWA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84115c57-5118-43e4-c455-87a0d08a63d5"
      },
      "source": [
        "# Using RDD\n",
        "rdd_twitter.map(lambda x: x[14]).distinct().count()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "133"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zOTfJzh9CmWA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9cfc6560-8e27-400e-9170-1f8b46755686"
      },
      "source": [
        "# Using DataFrame\n",
        "df_twitter.select(\"extracted_source\").distinct().count()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "133"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "epRtFuIfCmWA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c442fe9-5d05-4710-9a40-949a32020fa3"
      },
      "source": [
        "# Using spark.sql and the temporay table.\n",
        "spark.sql('''\n",
        "    SELECT COUNT (DISTINCT extracted_source) AS Unique_Extracted_Source\n",
        "    FROM twitter''').show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----------------------+\n",
            "|Unique_Extracted_Source|\n",
            "+-----------------------+\n",
            "|                    133|\n",
            "+-----------------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nv2-vv3OCmWA"
      },
      "source": [
        "#### 2.4 Get top 5 most used extracted_source"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SXCiTXooCmWB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "acc63153-dcb6-40de-affc-bdd45e07c3f0"
      },
      "source": [
        "# Using RDD (5 points)\n",
        "\n",
        "#Distinct extracted source\n",
        "ES = rdd_twitter.map(lambda x: x[14]).distinct()\n",
        "#Counting\n",
        "mapping = rdd_twitter.map(lambda x: x[14]).countByValue()\n",
        "#Now we can map using both just taking the 5 most used\n",
        "ES.takeOrdered(5,key=lambda x:-mapping[x])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Twitter for Android',\n",
              " 'Twitter for iPhone',\n",
              " 'Twitter Web App',\n",
              " 'Twitter for iPad',\n",
              " 'Twitter Web Client']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XnSMleM1CmWB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee9c1aa3-ae5a-41eb-a7d2-ed1c6e5c7a24"
      },
      "source": [
        "# Using DataFrame (2 points)\n",
        "df_twitter.groupby(\"extracted_source\").count().sort(col(\"count\").desc()).show(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-------------------+-----+\n",
            "|   extracted_source|count|\n",
            "+-------------------+-----+\n",
            "|Twitter for Android| 6262|\n",
            "| Twitter for iPhone| 5698|\n",
            "|    Twitter Web App| 2878|\n",
            "|   Twitter for iPad|  428|\n",
            "| Twitter Web Client|  136|\n",
            "+-------------------+-----+\n",
            "only showing top 5 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yHfliDf6CmWB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c2dab4d6-2ed4-45c4-d492-9952c50d9b8b"
      },
      "source": [
        "# Using spark.sql and the temporay table. (2 points)\n",
        "spark.sql('''\n",
        "        SELECT extracted_source, COUNT(extracted_source) AS Count_Extracted\n",
        "        FROM twitter\n",
        "        GROUP BY extracted_source \n",
        "        ORDER BY Count_Extracted DESC\n",
        "        LIMIT 5''').show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-------------------+---------------+\n",
            "|   extracted_source|Count_Extracted|\n",
            "+-------------------+---------------+\n",
            "|Twitter for Android|           6262|\n",
            "| Twitter for iPhone|           5698|\n",
            "|    Twitter Web App|           2878|\n",
            "|   Twitter for iPad|            428|\n",
            "| Twitter Web Client|            136|\n",
            "+-------------------+---------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KGQMiy3eCmWC"
      },
      "source": [
        "#### 2.5 Get count of distinct hastags used ( 5 point each) "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xKPNpdpAeEsz"
      },
      "source": [
        "import pyspark.sql.functions as F"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hXBAYChACmWD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e32c1169-1f53-4360-df8c-7f55e3942dd2"
      },
      "source": [
        "# Using RDD\n",
        "\n",
        "#flatmap allows me to use the list of hashtags\n",
        "rdd_twitter.flatMap(lambda x: x[2]).distinct().count()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1215"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xBzhA9C3CmWD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6bfb73f-bd74-477b-d20d-8e455f51bb33"
      },
      "source": [
        "# Using DataFrame\n",
        "df_twitter.select(F.explode(col('hashtags'))).distinct().count()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1215"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dERhvJyKCmWE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "161bc7fe-4cb5-411b-ec03-bd36578ac6e6"
      },
      "source": [
        "# Using spark.sql and the temporay table.\n",
        "spark.sql('''\n",
        "        SELECT COUNT(*) AS N_Unique_Hashtags FROM (SELECT DISTINCT EXPLODE(hashtags)\n",
        "        FROM twitter)''').show()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----------------+\n",
            "|N_Unique_Hashtags|\n",
            "+-----------------+\n",
            "|             1215|\n",
            "+-----------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NKRCUsojCmWE"
      },
      "source": [
        "#### 2.6 Get top 5 hashtags"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WVaOz8niCmWE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d6458d24-8c04-4c77-8579-5ab2c5367188"
      },
      "source": [
        "# Using RDD (4 points)\n",
        "\n",
        "#The explode function takes the list and \"unlist\" it\n",
        "df_twitter.select(F.explode(col('hashtags'))).groupby(\"col\").count().sort(col(\"count\").desc()).show(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------------+-----+\n",
            "|                 col|count|\n",
            "+--------------------+-----+\n",
            "|طبق_القدرات_للثان...|  385|\n",
            "|              Corona|  319|\n",
            "|            OilPrice|  251|\n",
            "|             COVID19|  125|\n",
            "|              corona|  123|\n",
            "+--------------------+-----+\n",
            "only showing top 5 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JDm27kPiCmWF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "572eb980-16bf-4e42-9942-daac121c615a"
      },
      "source": [
        "# Using DataFrame (2 points)\n",
        "df_twitter.select(F.explode(col('hashtags'))).groupby(\"col\").count().sort(col(\"count\").desc()).show(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------------+-----+\n",
            "|                 col|count|\n",
            "+--------------------+-----+\n",
            "|طبق_القدرات_للثان...|  385|\n",
            "|              Corona|  319|\n",
            "|            OilPrice|  251|\n",
            "|             COVID19|  125|\n",
            "|              corona|  123|\n",
            "+--------------------+-----+\n",
            "only showing top 5 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3fWwUibkCmWF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c83139d-dfe6-4637-b53a-571a78afe1cf"
      },
      "source": [
        "# Using spark.sql and the temporay table. (2 points)\n",
        "spark.sql('''SELECT hashtag, COUNT(hashtag) as Hashtag_Count FROM (SELECT EXPLODE(hashtags) as hashtag\n",
        "        FROM twitter)\n",
        "        GROUP BY hashtag\n",
        "        ORDER BY Hashtag_Count DESC\n",
        "        LIMIT 5''').show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------------+-------------+\n",
            "|             hashtag|Hashtag_Count|\n",
            "+--------------------+-------------+\n",
            "|طبق_القدرات_للثان...|          385|\n",
            "|              Corona|          319|\n",
            "|            OilPrice|          251|\n",
            "|             COVID19|          125|\n",
            "|              corona|          123|\n",
            "+--------------------+-------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "byQLCsWMCmWF"
      },
      "source": [
        "#### 2.6 Get total number of tweets which are retweeted more than 100 times"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k1lMtiR1CmWG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2fadb275-6668-475f-b650-8215545e2636"
      },
      "source": [
        "# Using RDD\n",
        "rdd_twitter.filter(lambda x: x[8]>100).count()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "15753"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sqEJ9HMcEadM",
        "outputId": "6b13ae79-2bc4-45bb-9da7-510684983ddc"
      },
      "source": [
        "# Using DataFrame\n",
        "df_twitter.filter(df_twitter.retweet_count > 100).count()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "15753"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2_lMuo1gCmWG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fab66f26-5f7f-4ae1-d5fd-77e6501f2d04"
      },
      "source": [
        "# Using spark.sql and the temporay table.\n",
        "spark.sql('''\n",
        "        SELECT COUNT(*) AS N_Tweets_More_100 FROM (\n",
        "            SELECT retweet_count \n",
        "            FROM twitter\n",
        "            WHERE retweet_count > 100)''').show()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----------------+\n",
            "|N_Tweets_More_100|\n",
            "+-----------------+\n",
            "|            15753|\n",
            "+-----------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3XJlg0vHCmWH"
      },
      "source": [
        "#### 2.8 Get top 3 most retweeted tweets per country (8 points)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OiFHMjRn5UfP",
        "outputId": "d4af7461-ca96-4d4d-f7b7-8d81570f82d2"
      },
      "source": [
        "for i,j in enumerate(df_twitter.columns):\n",
        "    print(\"Column\",i,\":\",j)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Column 0 : created_at\n",
            "Column 1 : favorite_count\n",
            "Column 2 : hashtags\n",
            "Column 3 : id\n",
            "Column 4 : in_reply_to_status_id\n",
            "Column 5 : in_reply_to_user_id_str\n",
            "Column 6 : location\n",
            "Column 7 : reply_count\n",
            "Column 8 : retweet_count\n",
            "Column 9 : source\n",
            "Column 10 : user_id_str\n",
            "Column 11 : user_followers_count\n",
            "Column 12 : user_created_at\n",
            "Column 13 : user_friends_count\n",
            "Column 14 : extracted_source\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zQ77xQrTCmWH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "30169a4b-7882-4866-ed95-151f8253ee26"
      },
      "source": [
        "import numpy as np\n",
        "# Using RDD\n",
        "rdd_twitter.map(lambda x: (x[6],[x[3],x[8]])).groupByKey().mapValues(lambda x: np.sort(list(x),axis=0)[-3:]).collect()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('India', array([['1252336674580791297', '9973'],\n",
              "         ['1252336682713649152', '9976'],\n",
              "         ['1252336686362738689', '9988']], dtype='<U19')),\n",
              " ('USA', array([['1252336697825689601', '9982'],\n",
              "         ['1252336698274562053', '9987'],\n",
              "         ['1252336700170424322', '9994']], dtype='<U19')),\n",
              " ('China', array([['1252336667735863296', '999'],\n",
              "         ['1252336671917510660', '9993'],\n",
              "         ['1252336676778545152', '9998']], dtype='<U19')),\n",
              " ('Pakistan', array([['1252336687037837312', '9973'],\n",
              "         ['1252336695778762752', '9975'],\n",
              "         ['1252336698320658436', '9988']], dtype='<U19')),\n",
              " ('Mexico', array([['1252336683644747776', '9971'],\n",
              "         ['1252336690284204032', '9994'],\n",
              "         ['1252336699230892040', '9998']], dtype='<U19')),\n",
              " ('UK', array([['1252336669778272256', '9985'],\n",
              "         ['1252336677395197953', '9989'],\n",
              "         ['1252336683753730057', '9991']], dtype='<U19')),\n",
              " ('Spain', array([['1252336686773800963', '9969'],\n",
              "         ['1252336699121664000', '9981'],\n",
              "         ['1252336700627521537', '9992']], dtype='<U19')),\n",
              " ('Canada', array([['1252336697469272066', '9987'],\n",
              "         ['1252336698245222400', '9992'],\n",
              "         ['1252336701294469120', '9997']], dtype='<U19')),\n",
              " ('Germany', array([['1252336672403947521', '9990'],\n",
              "         ['1252336672512962561', '9997'],\n",
              "         ['1252336686769434631', '9999']], dtype='<U19')),\n",
              " ('Chile', array([['1252336662773932032', '9978'],\n",
              "         ['1252336667010236416', '9984'],\n",
              "         ['1252336672265564160', '9988']], dtype='<U19')),\n",
              " ('Italy', array([['1252336679295373315', '9971'],\n",
              "         ['1252336682302488581', '9984'],\n",
              "         ['1252336687113355269', '9994']], dtype='<U19'))]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WP1geTazCmWH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff4973ea-82fe-421d-ce90-a97b8ada930d"
      },
      "source": [
        "# Using DataFrame\n",
        "from pyspark.sql.window import Window\n",
        "from pyspark.sql.functions import rank\n",
        "#Attain the rank of each row based on retweet count and location with the window,\n",
        "#Subsequently filter your results to only keep the first 3 values.\n",
        "df_twitter.select('id','location','retweet_count', rank().over(\n",
        "    Window().partitionBy(\"location\").orderBy(col(\"retweet_count\").desc()))\n",
        "    .alias('rank')).orderBy(col(\"retweet_count\").desc()).filter(col('rank') <= 3).sort(col(\"location\"),col(\"rank\").asc()).show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-------------------+--------+-------------+----+\n",
            "|                 id|location|retweet_count|rank|\n",
            "+-------------------+--------+-------------+----+\n",
            "|1252335430323888128|  Canada|         9997|   1|\n",
            "|1252254877939531776|  Canada|         9992|   2|\n",
            "|1252252082825986051|  Canada|         9987|   3|\n",
            "|1252253612140490759|   Chile|         9988|   1|\n",
            "|1252334891951427585|   Chile|         9984|   2|\n",
            "|1252253710182481920|   Chile|         9978|   3|\n",
            "|1252335780707684352|   China|         9998|   1|\n",
            "|1252253596516843520|   China|         9993|   2|\n",
            "|1252255562525560832|   China|         9984|   3|\n",
            "|1252334028092399622| Germany|         9999|   1|\n",
            "|1252330902325248000| Germany|         9997|   2|\n",
            "|1252252295510855682| Germany|         9990|   3|\n",
            "|1252332114948874240|   India|         9988|   1|\n",
            "|1252252336921206787|   India|         9976|   2|\n",
            "|1252254519116746754|   India|         9973|   3|\n",
            "|1252252106750377996|   Italy|         9994|   1|\n",
            "|1252251206027816960|   Italy|         9984|   2|\n",
            "|1252330500670337024|   Italy|         9971|   3|\n",
            "|1252253843145912320|  Mexico|         9998|   1|\n",
            "|1252255209776189442|  Mexico|         9994|   2|\n",
            "+-------------------+--------+-------------+----+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SGcLO0TPCmWH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a593494b-6e3d-4b6f-cd36-e6b0a6989626"
      },
      "source": [
        "# Using spark.sql and the temporay table.\n",
        "\n",
        "spark.sql('''SELECT id, location, retweet_count, rank\n",
        "FROM (SELECT id, location, retweet_count, dense_rank() OVER (\n",
        "    PARTITION BY location ORDER BY retweet_count DESC) as rank\n",
        "    FROM twitter)\n",
        "    WHERE rank <=3\n",
        "    ORDER BY location, rank ASC''').show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-------------------+--------+-------------+----+\n",
            "|                 id|location|retweet_count|rank|\n",
            "+-------------------+--------+-------------+----+\n",
            "|1252335430323888128|  Canada|         9997|   1|\n",
            "|1252254877939531776|  Canada|         9992|   2|\n",
            "|1252252082825986051|  Canada|         9987|   3|\n",
            "|1252253612140490759|   Chile|         9988|   1|\n",
            "|1252334891951427585|   Chile|         9984|   2|\n",
            "|1252253710182481920|   Chile|         9978|   3|\n",
            "|1252335780707684352|   China|         9998|   1|\n",
            "|1252253596516843520|   China|         9993|   2|\n",
            "|1252255562525560832|   China|         9984|   3|\n",
            "|1252334028092399622| Germany|         9999|   1|\n",
            "|1252330902325248000| Germany|         9997|   2|\n",
            "|1252252295510855682| Germany|         9990|   3|\n",
            "|1252332114948874240|   India|         9988|   1|\n",
            "|1252252336921206787|   India|         9976|   2|\n",
            "|1252254519116746754|   India|         9973|   3|\n",
            "|1252252106750377996|   Italy|         9994|   1|\n",
            "|1252251206027816960|   Italy|         9984|   2|\n",
            "|1252330500670337024|   Italy|         9971|   3|\n",
            "|1252253843145912320|  Mexico|         9998|   1|\n",
            "|1252255209776189442|  Mexico|         9994|   2|\n",
            "+-------------------+--------+-------------+----+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fmi2QJMXCmWI"
      },
      "source": [
        "#### 2.9 Total number of tweets per country"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4GTJNsozCmWI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "efd3c450-3c76-4962-d9a7-d7feab24530b"
      },
      "source": [
        "# Using RDD (3 points)\n",
        "rdd_twitter.map(lambda x: x[6]).countByValue()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "defaultdict(int,\n",
              "            {'Canada': 1441,\n",
              "             'Chile': 1410,\n",
              "             'China': 1457,\n",
              "             'Germany': 1426,\n",
              "             'India': 1480,\n",
              "             'Italy': 1422,\n",
              "             'Mexico': 1409,\n",
              "             'Pakistan': 1470,\n",
              "             'Spain': 1464,\n",
              "             'UK': 1376,\n",
              "             'USA': 1539})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YaIcBpftCmWI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5640649-73ae-40ff-9b50-b71d44633e7c"
      },
      "source": [
        "# Using DataFrame (2 points)\n",
        "df_twitter.groupby(\"location\").count().sort(col(\"count\")).show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------+-----+\n",
            "|location|count|\n",
            "+--------+-----+\n",
            "|      UK| 1376|\n",
            "|  Mexico| 1409|\n",
            "|   Chile| 1410|\n",
            "|   Italy| 1422|\n",
            "| Germany| 1426|\n",
            "|  Canada| 1441|\n",
            "|   China| 1457|\n",
            "|   Spain| 1464|\n",
            "|Pakistan| 1470|\n",
            "|   India| 1480|\n",
            "|     USA| 1539|\n",
            "+--------+-----+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BoD_Hwk3CmWJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6bf29271-9ab6-4f2d-f8a6-310179cccc66"
      },
      "source": [
        "# Using spark.sql and the temporay table. (1 point)\n",
        "spark.sql('''SELECT location, count(id)\n",
        "FROM twitter\n",
        "GROUP BY location\n",
        "ORDER BY count(id)''').show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------+---------+\n",
            "|location|count(id)|\n",
            "+--------+---------+\n",
            "|      UK|     1376|\n",
            "|  Mexico|     1409|\n",
            "|   Chile|     1410|\n",
            "|   Italy|     1422|\n",
            "| Germany|     1426|\n",
            "|  Canada|     1441|\n",
            "|   China|     1457|\n",
            "|   Spain|     1464|\n",
            "|Pakistan|     1470|\n",
            "|   India|     1480|\n",
            "|     USA|     1539|\n",
            "+--------+---------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7n1QBQsGCmWJ"
      },
      "source": [
        "## 3. Save Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C3VodvRcCmWJ"
      },
      "source": [
        "#### 3.1 save the data such that you have seperate folder per country (2 points)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "flfemMvJCmWJ"
      },
      "source": [
        "# Using DataFrame\n",
        "\n",
        "#I need to cast the only column that has arrays (hashtags) to string. Then I can save as CSV.\n",
        "#In order to save my dataframe grouped by country in different folders, I use the repartition() and partitionBy functions.\n",
        "\n",
        "df_twitter.withColumn(\"hashtags\", col(\"hashtags\").cast(\"string\")).repartition('location').write.partitionBy('location').csv(\"/content/saved_twitter_data\",header = 'true')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YV5Vr9XSNljR",
        "outputId": "d6e00bbc-3448-4a68-ff9b-6fa4e786e33d"
      },
      "source": [
        "#Let's check if everything is saved successfully.\n",
        "\n",
        "#!!! The file name changes everytime you execute the past code. Change it in order to read the csv file.!!!\n",
        "\n",
        "check_df = spark.read.csv(\"saved_twitter_data/location=UK/part-00132-7c56631a-b012-4d72-9256-eb530532aec4.c000.csv\",header='True')\n",
        "check_df.show(2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------------+--------------+--------+-------------------+---------------------+-----------------------+-----------+-------------+--------------------+-------------------+--------------------+--------------------+------------------+-------------------+\n",
            "|          created_at|favorite_count|hashtags|                 id|in_reply_to_status_id|in_reply_to_user_id_str|reply_count|retweet_count|              source|        user_id_str|user_followers_count|     user_created_at|user_friends_count|   extracted_source|\n",
            "+--------------------+--------------+--------+-------------------+---------------------+-----------------------+-----------+-------------+--------------------+-------------------+--------------------+--------------------+------------------+-------------------+\n",
            "|Mon Apr 20 15:01:...|          7682|      []|1252251164256555009|                 null|                   null|        418|         6513|<a href=\"http://t...|          346443880|                 208|Mon Aug 01 08:15:...|              1196|Twitter for Android|\n",
            "|Mon Apr 20 15:01:...|          9486|      []|1252251170845986816|                 null|                   null|       9506|         5558|<a href=\"http://t...|1247795796893814784|                   2|Wed Apr 08 08:00:...|                24| Twitter Web Client|\n",
            "+--------------------+--------------+--------+-------------------+---------------------+-----------------------+-----------+-------------+--------------------+-------------------+--------------------+--------------------+------------------+-------------------+\n",
            "only showing top 2 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7pmu4EprCmWK"
      },
      "source": [
        "#### 3.2 Save the data as parquet files (1 points)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wTrUhyOECmWK"
      },
      "source": [
        "# Using DataFrame\n",
        "df_twitter.repartition('location').write.partitionBy('location').parquet(\"twitter_location.as.parquet\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bfH6FYzCLYi6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "027156cb-7938-42a6-9f42-c9f08c98782a"
      },
      "source": [
        "#Let's check if everything is saved successfully.\n",
        "parquetFile = spark.read.parquet(\"twitter_location.as.parquet\")\n",
        "\n",
        "# Parquet files can also be used to create a temporary view and then used in SQL statements.\n",
        "parquetFile.createOrReplaceTempView(\"parquetFile\")\n",
        "spark.sql(\"SELECT * FROM parquetFile\").show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------------+--------------+--------------------+-------------------+---------------------+-----------------------+-----------+-------------+--------------------+-------------------+--------------------+--------------------+------------------+-------------------+--------+\n",
            "|          created_at|favorite_count|            hashtags|                 id|in_reply_to_status_id|in_reply_to_user_id_str|reply_count|retweet_count|              source|        user_id_str|user_followers_count|     user_created_at|user_friends_count|   extracted_source|location|\n",
            "+--------------------+--------------+--------------------+-------------------+---------------------+-----------------------+-----------+-------------+--------------------+-------------------+--------------------+--------------------+------------------+-------------------+--------+\n",
            "|Mon Apr 20 15:01:...|          5209|                  []|1252251170057457665|                 null|                   null|       6258|         7927|<a href=\"https://...|         1297207694|                9069|Mon Mar 25 01:08:...|              9109|    Twitter Web App|     USA|\n",
            "|Mon Apr 20 15:02:...|          2159|                  []|1252251177250668544|  1252251173140258819|    1246109551297994753|       2946|         2746|<a href=\"https://...|1246109551297994753|                 373|Fri Apr 03 16:18:...|              1664|    Twitter Web App|     USA|\n",
            "|Mon Apr 20 15:02:...|          7982|            [Corona]|1252251180627038209|                 null|                   null|        947|         1579|<a href=\"http://t...|          123283411|                  49|Mon Mar 15 15:55:...|               114|Twitter for Android|     USA|\n",
            "|Mon Apr 20 15:02:...|          9733|                  []|1252251181814108161|                 null|                   null|       8461|         4521|<a href=\"http://t...|1176478702772850689|                  64|Tue Sep 24 12:49:...|                77| Twitter for iPhone|     USA|\n",
            "|Mon Apr 20 15:02:...|          6059|                  []|1252251182426476548|                 null|                   null|       3180|         5003|<a href=\"http://t...|1175615769176170496|                 562|Sun Sep 22 03:40:...|               804|Twitter for Android|     USA|\n",
            "|Mon Apr 20 15:02:...|          5372|         [COVIDー19]|1252251184385179648|                 null|                   null|       5910|         5155|<a href=\"https://...|         1432406870|               16482|Thu May 16 07:36:...|                49|          TweetDeck|     USA|\n",
            "|Mon Apr 20 15:02:...|          8225|[Coronavirus, COV...|1252251194849976320|                 null|                   null|       7901|         9049|<a href=\"http://t...| 845916368960602112|                  41|Sun Mar 26 08:32:...|                90|Twitter for Android|     USA|\n",
            "|Mon Apr 20 15:02:...|          5238|                  []|1252251196628373505|                 null|                   null|        159|         4333|<a href=\"http://t...|           64797438|                1870|Tue Aug 11 19:27:...|              1301| Twitter for iPhone|     USA|\n",
            "|Mon Apr 20 15:02:...|          6584|                  []|1252251200084414466|                 null|                   null|       2897|         8886|<a href=\"https://...|         3699496906|               21503|Fri Sep 18 19:16:...|             23042|    Twitter Web App|     USA|\n",
            "|Mon Apr 20 15:02:...|          8579|                  []|1252251204047888390|                 null|                   null|       7980|         6108|<a href=\"https://...|          106584640|                 557|Wed Jan 20 01:21:...|               672|          TweetDeck|     USA|\n",
            "|Mon Apr 20 15:02:...|          6679|                  []|1252251217239171074|                 null|                   null|       7184|         3336|<a href=\"http://t...|1252166317899231234|                  54|Mon Apr 20 09:25:...|               408|Twitter for Android|     USA|\n",
            "|Mon Apr 20 15:02:...|          2626|[NUFCTakeover, NUFC]|1252251217075585024|                 null|                   null|       7515|         7569|<a href=\"http://t...|          262667747|                1439|Tue Mar 08 14:22:...|              2557|Twitter for Android|     USA|\n",
            "|Mon Apr 20 15:02:...|          2040|                  []|1252251217952215044|                 null|                   null|       5881|         9399|<a href=\"http://t...|          279717243|                 809|Sat Apr 09 21:34:...|              1135|Twitter for Android|     USA|\n",
            "|Mon Apr 20 15:02:...|          7668|                  []|1252251221286502405|                 null|                   null|       1910|         6904|<a href=\"https://...|           14057781|                4174|Thu Feb 28 22:55:...|              4120|          TweetDeck|     USA|\n",
            "|Mon Apr 20 15:02:...|          4392|                  []|1252251224512102407|                 null|                   null|       2026|         3940|<a href=\"http://t...| 984047261557587968|                 125|Wed Apr 11 12:35:...|              1030| Twitter for iPhone|     USA|\n",
            "|Mon Apr 20 15:02:...|          9840|                  []|1252251241801027586|                 null|                   null|       6238|         8917|<a href=\"http://t...|         1602168482|                2966|Thu Jul 18 00:32:...|              2010| Twitter for iPhone|     USA|\n",
            "|Mon Apr 20 15:02:...|          9929|                  []|1252251245298896899|                 null|                   null|        845|         5820|<a href=\"https://...|           89085290|                4055|Wed Nov 11 02:24:...|              4977|    Twitter Web App|     USA|\n",
            "|Mon Apr 20 15:02:...|           414|                  []|1252251250130931712|                 null|                   null|       8938|         6242|<a href=\"http://t...|1046769171047084037|                 148|Mon Oct 01 14:29:...|               133| Twitter for iPhone|     USA|\n",
            "|Mon Apr 20 15:02:...|          5033|                  []|1252251268208381953|                 null|                   null|       5080|         7548|<a href=\"http://t...| 827625660164272128|                  80|Fri Feb 03 21:11:...|               231| Twitter for iPhone|     USA|\n",
            "|Mon Apr 20 15:02:...|          7814|                  []|1252251270275977216|                 null|                   null|       5719|         9534|<a href=\"http://t...|         1076145517|                   7|Thu Jan 10 09:27:...|                83| Twitter for iPhone|     USA|\n",
            "+--------------------+--------------+--------------------+-------------------+---------------------+-----------------------+-----------+-------------+--------------------+-------------------+--------------------+--------------------+------------------+-------------------+--------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}