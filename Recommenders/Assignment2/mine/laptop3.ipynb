{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-08T16:53:14.558055Z",
     "start_time": "2021-04-08T16:53:14.543030Z"
    },
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../kaggle/input\\movielens-fds\\movielens-fds.zip\n",
      "../kaggle/input\\movielens-fds\\sample_submission.csv\n",
      "../kaggle/input\\movielens-fds\\test.csv\n",
      "../kaggle/input\\movielens-fds\\training.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pylab as plt\n",
    "import time\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('../kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-08T16:53:15.129762Z",
     "start_time": "2021-04-08T16:53:15.117760Z"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate(predict_f,data_test):\n",
    "    \"\"\" RMSE-based predictive performance evaluation with pandas. \"\"\"\n",
    "    ids_to_estimate = zip(data_test.user_id, data_test.movie_id)\n",
    "    estimated = np.array([predict_f(u,i) for (u,i) in ids_to_estimate ])\n",
    "    real = data_test.rating.values\n",
    "    return compute_rmse(estimated, real)\n",
    "\n",
    "\n",
    "def compute_rmse(y_pred, y_true):\n",
    "    \"\"\" Compute Root Mean Squared Error. \"\"\"\n",
    "    return np.sqrt(np.mean(np.power(y_pred - y_true, 2)))\n",
    "\n",
    "\n",
    "## Divide the data in two sets: training and test\n",
    "def assign_to_set(df):\n",
    "    sampled_ids = np.random.choice(df.index,\n",
    "                                   size=np.int64(np.ceil(df.index.size * 0.05)),\n",
    "                                   replace=False)\n",
    "    df['for_testing'] = False\n",
    "    df.loc[sampled_ids, 'for_testing'] = True\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-08T16:53:24.257763Z",
     "start_time": "2021-04-08T16:53:23.536716Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('../kaggle/input/movielens-fds/training.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-08T16:53:26.092357Z",
     "start_time": "2021-04-08T16:53:26.085359Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(945180, 5)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-08T16:53:29.660849Z",
     "start_time": "2021-04-08T16:53:28.738685Z"
    }
   },
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('../kaggle/input/movielens-fds/test.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-08T16:53:32.000960Z",
     "start_time": "2021-04-08T16:53:31.926957Z"
    }
   },
   "outputs": [],
   "source": [
    "df = df.sample(100235)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df_test.sample(972)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-08T16:53:32.915125Z",
     "start_time": "2021-04-08T16:53:32.900123Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(848600, 4)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-08T16:53:37.386213Z",
     "start_time": "2021-04-08T16:53:36.805798Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "def genre_categorical(df):\n",
    "    \n",
    "\n",
    "    df['Genres_list'] = df['genre'].str.split('|')\n",
    "\n",
    "    ## assign a new series to the genres_list column that contains a list of categories for each movie\n",
    "    list2series = pd.Series(df.Genres_list)\n",
    "\n",
    "    mlb = MultiLabelBinarizer()\n",
    "\n",
    "    ## use mlb to create a new dataframe of the genres from the list for each row from the original data\n",
    "\n",
    "    one_hot_genres = pd.DataFrame(mlb.fit_transform(list2series),columns=mlb.classes_,index=list2series.index)\n",
    "    \n",
    "    df = df.drop([\"Genres_list\",\"title\",\"genre\"],axis=1)\n",
    "    \n",
    "    return pd.merge(df,one_hot_genres, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-08T16:53:40.213078Z",
     "start_time": "2021-04-08T16:53:37.387171Z"
    }
   },
   "outputs": [],
   "source": [
    "df = genre_categorical(df)\n",
    "df_test = genre_categorical(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-08T16:53:40.244042Z",
     "start_time": "2021-04-08T16:53:40.215068Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>(no genres listed)</th>\n",
       "      <th>Action</th>\n",
       "      <th>Adventure</th>\n",
       "      <th>Animation</th>\n",
       "      <th>Children</th>\n",
       "      <th>Comedy</th>\n",
       "      <th>Crime</th>\n",
       "      <th>Documentary</th>\n",
       "      <th>...</th>\n",
       "      <th>Film-Noir</th>\n",
       "      <th>Horror</th>\n",
       "      <th>IMAX</th>\n",
       "      <th>Musical</th>\n",
       "      <th>Mystery</th>\n",
       "      <th>Romance</th>\n",
       "      <th>Sci-Fi</th>\n",
       "      <th>Thriller</th>\n",
       "      <th>War</th>\n",
       "      <th>Western</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1762</td>\n",
       "      <td>307</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1762</td>\n",
       "      <td>67534</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1762</td>\n",
       "      <td>2317</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1762</td>\n",
       "      <td>94011</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1762</td>\n",
       "      <td>164725</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  movie_id  (no genres listed)  Action  Adventure  Animation  \\\n",
       "0     1762       307                   0       0          0          0   \n",
       "1     1762     67534                   0       0          0          0   \n",
       "2     1762      2317                   0       0          0          0   \n",
       "3     1762     94011                   0       1          0          0   \n",
       "4     1762    164725                   0       0          0          0   \n",
       "\n",
       "   Children  Comedy  Crime  Documentary  ...  Film-Noir  Horror  IMAX  \\\n",
       "0         0       0      0            0  ...          0       0     0   \n",
       "1         0       1      0            0  ...          0       0     0   \n",
       "2         0       1      0            0  ...          0       0     0   \n",
       "3         0       0      0            0  ...          0       0     0   \n",
       "4         1       1      0            0  ...          0       0     0   \n",
       "\n",
       "   Musical  Mystery  Romance  Sci-Fi  Thriller  War  Western  \n",
       "0        0        0        0       0         0    0        0  \n",
       "1        0        0        0       0         0    0        0  \n",
       "2        0        0        0       0         0    0        0  \n",
       "3        0        0        0       0         1    0        0  \n",
       "4        0        0        0       0         0    0        0  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-08T16:53:52.362297Z",
     "start_time": "2021-04-08T16:53:40.249072Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>(no genres listed)</th>\n",
       "      <th>Action</th>\n",
       "      <th>Adventure</th>\n",
       "      <th>Animation</th>\n",
       "      <th>Children</th>\n",
       "      <th>Comedy</th>\n",
       "      <th>Crime</th>\n",
       "      <th>...</th>\n",
       "      <th>Film-Noir</th>\n",
       "      <th>Horror</th>\n",
       "      <th>IMAX</th>\n",
       "      <th>Musical</th>\n",
       "      <th>Mystery</th>\n",
       "      <th>Romance</th>\n",
       "      <th>Sci-Fi</th>\n",
       "      <th>Thriller</th>\n",
       "      <th>War</th>\n",
       "      <th>Western</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>148657</th>\n",
       "      <td>4912</td>\n",
       "      <td>832</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280599</th>\n",
       "      <td>1818</td>\n",
       "      <td>2916</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256760</th>\n",
       "      <td>7968</td>\n",
       "      <td>2541</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>720976</th>\n",
       "      <td>9576</td>\n",
       "      <td>37386</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353722</th>\n",
       "      <td>9357</td>\n",
       "      <td>5481</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        user_id  movie_id  rating  (no genres listed)  Action  Adventure  \\\n",
       "148657     4912       832     5.0                   0       0          0   \n",
       "280599     1818      2916     4.0                   0       1          1   \n",
       "256760     7968      2541     2.5                   0       0          0   \n",
       "720976     9576     37386     1.0                   0       1          0   \n",
       "353722     9357      5481     3.0                   0       0          0   \n",
       "\n",
       "        Animation  Children  Comedy  Crime  ...  Film-Noir  Horror  IMAX  \\\n",
       "148657          0         0       0      1  ...          0       0     0   \n",
       "280599          0         0       0      0  ...          0       0     0   \n",
       "256760          0         0       0      0  ...          0       0     0   \n",
       "720976          0         0       0      0  ...          0       0     0   \n",
       "353722          0         0       1      0  ...          0       0     0   \n",
       "\n",
       "        Musical  Mystery  Romance  Sci-Fi  Thriller  War  Western  \n",
       "148657        0        0        0       0         1    0        0  \n",
       "280599        0        0        0       1         1    0        0  \n",
       "256760        0        0        0       0         0    0        0  \n",
       "720976        0        0        0       1         0    0        0  \n",
       "353722        0        0        0       0         0    0        0  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped    = df.groupby('user_id', group_keys=False).apply(assign_to_set)\n",
    "df_train = df[grouped.for_testing == False]\n",
    "df_val   = df[grouped.for_testing == True]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-08T16:53:52.377298Z",
     "start_time": "2021-04-08T16:53:52.363299Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100235, 23)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-08T16:55:09.928458Z",
     "start_time": "2021-04-08T16:55:09.890422Z"
    }
   },
   "outputs": [],
   "source": [
    "class FM():\n",
    "    def __init__(self,k = 40,learning_rate = 10,solver='stochastic',iterations = 100,regularizer = 0.00035,verbose = True):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.solver=solver\n",
    "        self.k = k\n",
    "        self.iterations = iterations\n",
    "        self.indices = {}\n",
    "        self.regularizer = regularizer\n",
    "        self.verbose = verbose\n",
    "        \n",
    "        \n",
    "    def set_indices(self,X):\n",
    "        i = 0\n",
    "        cols = {}\n",
    "        for col in X.columns:\n",
    "            cols[col] = i\n",
    "            i += 1\n",
    "\n",
    "        indices = {}\n",
    "        nz = 0\n",
    "        for col in X.columns:\n",
    "            if X[col].dtype == 'object':\n",
    "                indices[cols[col]] = {}\n",
    "                colset = set(X[col])\n",
    "                for a in colset:\n",
    "                    indices[cols[col]][a] = nz\n",
    "                    nz += 1\n",
    "            else:\n",
    "                indices[cols[col]] = nz\n",
    "                nz += 1\n",
    "        self.indices = indices\n",
    "        self.nz = nz\n",
    "        \n",
    "    \n",
    "    def getIndexVal(self, col, val):\n",
    "        if isinstance(self.indices[col], int) or isinstance(self.indices[col], float):\n",
    "            return self.indices[col], val\n",
    "        else:\n",
    "            try:\n",
    "                return self.indices[col][val], 1.\n",
    "            except:\n",
    "                #print(col, val)\n",
    "                return 0., 0.\n",
    "            \n",
    "    def getIndexValArray(self, arr):\n",
    "        out = []\n",
    "        for i in range(len(arr)):\n",
    "            out.append(self.getIndexVal(i, arr[i]))\n",
    "        return out\n",
    "    \n",
    "    def initialize_params(self, X, y):\n",
    "        self.set_indices(X)\n",
    "        self.w0 = np.mean(y)\n",
    "        self.w1 = np.zeros(self.nz)\n",
    "        self.v = np.random.normal(scale=0.1,size=(self.nz, self.k))\n",
    "        \n",
    "    def sgd(self, X, y, verbose = True):\n",
    "\n",
    "        learning_rate = self.learning_rate\n",
    "        regularizer = self.regularizer\n",
    "        w0 = self.w0\n",
    "        w1 = self.w1\n",
    "        v = self.v\n",
    "        nz = self.nz\n",
    "\n",
    "        m = X.shape[0]\n",
    "        n = X.shape[1]\n",
    "        \n",
    "        #SGD\n",
    "        for epoch in range(self.iterations):\n",
    "            start_time = time.perf_counter()\n",
    "\n",
    "            preds = []\n",
    "            for i in range(m):\n",
    "\n",
    "                _x = X[i, :]\n",
    "                _ivals = self.getIndexValArray(_x)\n",
    "                ind = {}\n",
    "                sum1 = 0\n",
    "                sum2 = 0\n",
    "                sum3 = np.zeros(self.k)\n",
    "\n",
    "                for col in range(n):\n",
    "                    index, val = _ivals[col]\n",
    "                    ind[index] = val\n",
    "                    sum1 += w1[index] * val\n",
    "\n",
    "                for f in range(self.k):\n",
    "                    s1 = 0.0\n",
    "                    s2 = 0.0\n",
    "                    for col in range(n):\n",
    "                        index, val = _ivals[col]\n",
    "                        temp = v[index, f] * val\n",
    "                        s1 += temp\n",
    "                        s2 += temp*temp\n",
    "                    sum3[f] = s1\n",
    "                    sum2 += s1*s1 - s2\n",
    "\n",
    "                y_hat = w0 + sum1 + 0.5*sum2\n",
    "                y_hat = max(1., y_hat)\n",
    "                y_hat = min(5., y_hat)\n",
    "                res = (y_hat - y[i])\n",
    "                if self.verbose:\n",
    "                    preds.append(abs(res)**2)\n",
    "\n",
    "                b = learning_rate*regularizer\n",
    "                # update rule for w0\n",
    "                w0 = w0 - learning_rate * res - learning_rate * w0 * regularizer\n",
    "\n",
    "                for col in range(n):\n",
    "                    #index = col\n",
    "                    #if col in ind:\n",
    "                    #    val = ind[col]\n",
    "                    index, val = _ivals[col]\n",
    "                    temp = learning_rate * val * res\n",
    "                    w1[index] -= (temp + b*w1[index])\n",
    "                    for f in range(self.k):\n",
    "                        v[index, f] -= (temp * (sum3[f] - v[index, f] * val) + b*v[index, f])\n",
    "                    #else:\n",
    "                    #    w1[index] -= b*w1[index]\n",
    "                    #    for f in range(self.k):\n",
    "                    #        v[index, f] -= b*v[index, f]\n",
    "\n",
    "            print(\"epoch {} time {} mse {}\".format(epoch, time.perf_counter()-start_time, np.mean(preds)))\n",
    "        self.w0 = w0\n",
    "        self.w1 = w1\n",
    "        self.v = v\n",
    "    \n",
    "    \n",
    "    def fit(self,X,y):\n",
    "        self.initialize_params(X, y)\n",
    "        X = np.array(X)\n",
    "        y = np.array(y)\n",
    "        self.sgd(X, y)\n",
    "        return\n",
    "    \n",
    "    def predict(self, X, verbose=True):\n",
    "\n",
    "        X = np.array(X)\n",
    "        \n",
    "        w0 = self.w0\n",
    "        w1 = self.w1\n",
    "        v = self.v\n",
    "        nz = self.nz\n",
    "\n",
    "        \n",
    "        m = X.shape[0]\n",
    "        n = X.shape[1]\n",
    "\n",
    "        preds = []\n",
    "        for i in range(m):\n",
    "\n",
    "\n",
    "            _x = X[i, :]\n",
    "            _ivals = self.getIndexValArray(_x)\n",
    "            ind = {}\n",
    "            sum1 = 0\n",
    "            sum2 = 0\n",
    "            sum3 = np.zeros(self.k)\n",
    "\n",
    "            for col in range(n):\n",
    "\n",
    "                index, val = _ivals[col]\n",
    "                ind[index] = val\n",
    "\n",
    "                index = int(index)\n",
    "\n",
    "                sum1 += w1[index] * val\n",
    "\n",
    "\n",
    "            for f in range(self.k):\n",
    "                s1 = 0\n",
    "                s2 = 0\n",
    "                for col in range(n):\n",
    "                    index, val = _ivals[col]\n",
    "                    index = int(index)\n",
    "                    temp = v[index, f] * val\n",
    "                    s1 += temp\n",
    "                    s2 += temp*temp\n",
    "                sum3[f] = s1\n",
    "                s1 = s1*s1\n",
    "                sum2 += s1 - s2\n",
    "\n",
    "            y_hat = w0 + sum1 + 0.5*sum2\n",
    "            y_hat = max(1., y_hat)\n",
    "            y_hat = min(5., y_hat)\n",
    "            preds.append(y_hat)\n",
    "\n",
    "        return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df.sample(frac=0.8,random_state=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val=df.drop(df_train.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-08T16:53:59.067808Z",
     "start_time": "2021-04-08T16:53:59.020775Z"
    }
   },
   "outputs": [],
   "source": [
    "val = df_val.copy()\n",
    "train = df_train.copy()\n",
    "\n",
    "test = df_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-08T16:54:01.001466Z",
     "start_time": "2021-04-08T16:53:59.653810Z"
    }
   },
   "outputs": [],
   "source": [
    "y_train = train['rating']\n",
    "train.drop(['rating'], axis=1, inplace=True)\n",
    "\n",
    "train['user_id'] = train['user_id'].astype('str')\n",
    "train['movie_id'] = train['movie_id'].astype('str')\n",
    "\n",
    "y_val = val[\"rating\"]\n",
    "val.drop(['rating'], axis=1, inplace=True)\n",
    "val['user_id'] = val['user_id'].astype('str')\n",
    "val['movie_id'] = val['movie_id'].astype('str')\n",
    "\n",
    "test['user_id'] = test['user_id'].astype('str')\n",
    "test['movie_id'] = test['movie_id'].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-08T16:54:01.017445Z",
     "start_time": "2021-04-08T16:54:01.006426Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: (89249, 22) \n",
      "y_train size: (10986, 22) \n",
      "test size: (848600, 22)\n"
     ]
    }
   ],
   "source": [
    "print(\"Train size:\",train.shape,\n",
    "     \"\\ny_train size:\",val.shape,\n",
    "     \"\\ntest size:\",test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-08T16:55:13.797544Z",
     "start_time": "2021-04-08T16:55:13.783510Z"
    }
   },
   "outputs": [],
   "source": [
    "f = FM(k=10, iterations = 60, learning_rate = 0.01, regularizer=0.03)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-08T17:55:53.815771Z",
     "start_time": "2021-04-08T16:55:13.997510Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 time 66.14670619999742 mse 1.038081298853243\n",
      "epoch 1 time 65.90673369999786 mse 0.9135895171385224\n",
      "epoch 2 time 65.82545670000036 mse 0.8605316949941623\n",
      "epoch 3 time 65.96206449999954 mse 0.8261342859648161\n",
      "epoch 4 time 66.35091670000111 mse 0.7999291877257593\n",
      "epoch 5 time 66.68685040000128 mse 0.7780658660143074\n",
      "epoch 6 time 66.26934290000281 mse 0.7587121477313422\n",
      "epoch 7 time 66.62225419999959 mse 0.7408600628518739\n",
      "epoch 8 time 66.13566210000135 mse 0.7239083339808544\n",
      "epoch 9 time 66.27244479999717 mse 0.7074822430556812\n",
      "epoch 10 time 66.3075523999978 mse 0.6913463356710418\n",
      "epoch 11 time 66.59072450000167 mse 0.6753570992269241\n",
      "epoch 12 time 66.60134239999752 mse 0.6594503413946365\n",
      "epoch 13 time 65.71159140000236 mse 0.6436042554329985\n",
      "epoch 14 time 66.63661649999995 mse 0.6278103096220201\n",
      "epoch 15 time 66.56197020000036 mse 0.6120840360520245\n",
      "epoch 16 time 67.52666389999649 mse 0.5964594664132343\n",
      "epoch 17 time 66.76082479999968 mse 0.58098492586508\n",
      "epoch 18 time 65.97788579999906 mse 0.5657083643524577\n",
      "epoch 19 time 61.141545899998164 mse 0.5506704585616047\n",
      "epoch 20 time 60.03292499999952 mse 0.535919202230333\n",
      "epoch 21 time 59.588202900002216 mse 0.5214915715931595\n",
      "epoch 22 time 60.07308329999796 mse 0.5074162664361734\n",
      "epoch 23 time 61.51633569999831 mse 0.4937083108653682\n",
      "epoch 24 time 60.22441799999797 mse 0.4803833253722148\n",
      "epoch 25 time 62.277064699999755 mse 0.46745432920970414\n",
      "epoch 26 time 64.76354609999908 mse 0.4549324468195267\n",
      "epoch 27 time 59.4563507999992 mse 0.4428125853723059\n",
      "epoch 28 time 58.188168299999234 mse 0.43110635270761766\n",
      "epoch 29 time 58.23570549999931 mse 0.4198158237238998\n",
      "epoch 30 time 58.049256199999945 mse 0.40893878601870215\n",
      "epoch 31 time 57.464080300000205 mse 0.398468450100843\n",
      "epoch 32 time 57.213864000001195 mse 0.38839820489681803\n",
      "epoch 33 time 57.819434099998034 mse 0.3787188144845204\n",
      "epoch 34 time 57.42461139999796 mse 0.3694207882799596\n",
      "epoch 35 time 57.96351180000056 mse 0.36049187076149475\n",
      "epoch 36 time 57.258065500001976 mse 0.3519210668966039\n",
      "epoch 37 time 57.1700110999991 mse 0.3436993861102079\n",
      "epoch 38 time 57.68609949999882 mse 0.33581587290199205\n",
      "epoch 39 time 57.35604009999952 mse 0.32825496431345763\n",
      "epoch 40 time 56.963178699999844 mse 0.32100259967107514\n",
      "epoch 41 time 56.844037499999104 mse 0.3140425581640665\n",
      "epoch 42 time 57.450605499998346 mse 0.30737040007674654\n",
      "epoch 43 time 56.83884970000145 mse 0.3009732204425599\n",
      "epoch 44 time 57.13280269999814 mse 0.29483806159866877\n",
      "epoch 45 time 57.418675599998096 mse 0.28895536119206716\n",
      "epoch 46 time 56.528480000000854 mse 0.2833149691145666\n",
      "epoch 47 time 56.850761699999566 mse 0.27790682185736554\n",
      "epoch 48 time 56.84932540000227 mse 0.27271811285069886\n",
      "epoch 49 time 56.695449100003316 mse 0.2677410214428493\n",
      "epoch 50 time 56.79631860000154 mse 0.2629641800521114\n",
      "epoch 51 time 56.52347629999713 mse 0.2583789433399064\n",
      "epoch 52 time 56.72103699999934 mse 0.25397635650755773\n",
      "epoch 53 time 56.54771069999697 mse 0.24975092027572543\n",
      "epoch 54 time 57.30741240000134 mse 0.24569275176929015\n",
      "epoch 55 time 56.71040290000019 mse 0.24179481196798464\n",
      "epoch 56 time 56.788293199999316 mse 0.23804899698661217\n",
      "epoch 57 time 56.705411200000526 mse 0.2344516660738945\n",
      "epoch 58 time 57.00121609999769 mse 0.23094869714683328\n",
      "epoch 59 time 56.81864450000285 mse 0.22760168620479948\n"
     ]
    }
   ],
   "source": [
    "f.fit(X=train, y=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0.75\n",
    "0.89"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1094+1092+1089+1093+1090"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-08T17:55:56.632276Z",
     "start_time": "2021-04-08T17:55:53.817737Z"
    }
   },
   "outputs": [],
   "source": [
    "y_pred = f.predict(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-08T17:55:56.679271Z",
     "start_time": "2021-04-08T17:55:56.633236Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sqrt(2.7410814585956933)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-08T17:55:56.694271Z",
     "start_time": "2021-04-08T17:55:56.681238Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 1.2562889669833912\n"
     ]
    }
   ],
   "source": [
    "print(\"MSE: {}\".format(mean_squared_error(y_val, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"MSE: {}\".format(mean_squared_error(y_val, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0.96\n",
    "1.3\n",
    "1.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-08T17:59:19.265330Z",
     "start_time": "2021-04-08T17:55:56.695236Z"
    }
   },
   "outputs": [],
   "source": [
    "testPred=f.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import sparse\n",
    "\n",
    "\n",
    "class RecSys_vanilla_mf_biases():\n",
    "    \"\"\" Collaborative filtering using a custom sim(u,u'). \"\"\"\n",
    "\n",
    "    def __init__(self,df_train,df_val, num_components=10):\n",
    "        \"\"\" Constructor \"\"\"\n",
    "        self.df_train = df_train\n",
    "        self.df_val = df_val\n",
    "        self.num_components=num_components\n",
    "        self.train = pd.pivot_table(self.df_train[['user_id','movie_id','rating']],columns='movie_id',index='user_id',values='rating')\n",
    "        \n",
    "        # We create a dictionary where we will store the user_id and movie_id which correspond \n",
    "        # to each index in the Rating matrix\n",
    "        \n",
    "        user_index = np.arange(len(self.train.index))\n",
    "        self.users = dict(zip(user_index,self.train.index ))\n",
    "        self.users_id2index = dict(zip(self.train.index,user_index)) \n",
    "        \n",
    "        movie_index = np.arange(len(self.train.columns))\n",
    "        self.movies = dict(zip(movie_index,self.train.columns )) \n",
    "        self.movies_id2index= dict(zip(self.train.columns, movie_index))\n",
    "        self.movies_index2id= dict(zip(movie_index,self.train.columns))\n",
    "        self.movie_id2title = dict(df.groupby(by=['movie_id','title']).count().index)\n",
    "    \n",
    "    def __sdg__(self):\n",
    "        for idx in self.training_indices:\n",
    "            u = self.sample_row[idx]\n",
    "            i = self.sample_col[idx]\n",
    "            user_id = self.users[u]\n",
    "            item_id = self.movies[i]\n",
    "            \n",
    "            prediction = self.predict(user_id, item_id)\n",
    "            error = (self.ratings[u,i] - prediction) # error\n",
    "            #Update latent factors\n",
    "            self.user_vecs[u, :] += self.learning_rate * \\\n",
    "                                    (error * self.item_vecs[i, :] - self.lmbda * self.user_vecs[u,:])\n",
    "            self.item_vecs[i, :] += self.learning_rate * \\\n",
    "                                    (error * self.user_vecs[u, :] - self.lmbda * self.item_vecs[i,:])\n",
    "            \n",
    "            self.bias_item[i] += self.learning_rate * (error - self.lmbda * self.bias_item[i]) \n",
    "            self.bias_user[u] += self.learning_rate * (error - self.lmbda * self.bias_user[u]) \n",
    "                \n",
    "                \n",
    "    def fit(self,n_epochs = 10,learning_rate =0.001,lmbda=0.1,verbose =True):\n",
    "        \"\"\" We decompose the R matrix into to submatrices using the training data \"\"\"\n",
    "        self.verbose = verbose\n",
    "        self.learning_rate = learning_rate\n",
    "        self.lmbda = lmbda\n",
    "        \n",
    "        self.ratings = np.float32(self.train.fillna(0).values)\n",
    "        self.mean_rating = self.ratings[self.ratings>0].mean() \n",
    "        self.n_users, self.n_items = self.train.shape\n",
    "        self.sample_row, self.sample_col = self.ratings.nonzero()\n",
    "        self.n_samples = len(self.sample_row)\n",
    "        \n",
    "        self.train_rmse =[]\n",
    "        self.test_rmse = []\n",
    "        iter_diff = 0\n",
    "        \n",
    "        # initialize latent vectors\n",
    "        self.user_vecs = np.random.normal(scale=1./self.num_components,\\\n",
    "                                          size=(self.n_users, self.num_components))\n",
    "        self.item_vecs = np.random.normal(scale=1./self.num_components,\n",
    "                                          size=(self.n_items, self.num_components))\n",
    "        self.bias_item = np.random.normal(scale=1/self.n_items,size=(self.n_items))\n",
    "        self.bias_user = np.random.normal(scale=1/self.n_users,size=(self.n_users))\n",
    "        \n",
    "\n",
    "        for epoch in range(n_epochs):\n",
    "            print('Epoch: {}'.format(epoch))\n",
    "            \n",
    "            self.training_indices = np.arange(self.n_samples)\n",
    "            \n",
    "            #shuffle training samples\n",
    "            np.random.shuffle(self.training_indices)\n",
    "            self.__sdg__()\n",
    "            \n",
    "            self.train_rmse.append(evaluate(self.predict,self.df_train))\n",
    "            self.test_rmse.append(evaluate(self.predict,self.df_val))\n",
    "            \n",
    "            \n",
    "            print('\\tTrain rmse: %s' % self.train_rmse[-1])\n",
    "            print('\\tTest rmse: %s' % self.test_rmse[-1])\n",
    "            \n",
    "        \n",
    "        if(self.verbose):\n",
    "            self.__plot_learning_curves__()\n",
    "    \n",
    "    def __plot_learning_curves__(self):\n",
    "        plt.plot(self.train_rmse,'--o',label=\"train_error\")\n",
    "        plt.plot(self.test_rmse,'--o',label=\"test_error\")\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "        \n",
    "    def predict(self, user_id, movie_id):\n",
    "        \"\"\" Single user and item prediction.\"\"\"\n",
    "        if(user_id in self.users_id2index):\n",
    "            user_index = self.users_id2index[user_id]\n",
    "        else:\n",
    "            return 3 #cold start user\n",
    "        if movie_id in self.movies_id2index:\n",
    "            item_index = self.movies_id2index[movie_id]\n",
    "            prediction =  self.mean_rating + self.user_vecs[user_index, :].dot(self.item_vecs[item_index, :].T) + self.bias_item[item_index] + self.bias_user[user_index]\n",
    "        else:\n",
    "            prediction = self.mean_rating # this is a new movie\n",
    "\n",
    "        return prediction\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reco = RecSys_vanilla_mf_biases(training,val,num_components=5)\n",
    "reco.fit(n_epochs = 5,learning_rate=0.01,lmbda=0.5)\n",
    "print('RMSE for Collaborative Recomender: %s' % evaluate(reco.predict,df_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#estimate all pairs of user_id/movie_id from the test set\n",
    "ids_to_estimate = zip(df_test.user_id, df_test.movie_id)\n",
    "estimated = np.array([reco.predict(u,i) for (u,i) in ids_to_estimate ])\n",
    "\n",
    "# generate the submission file\n",
    "df_test['estimated'] = estimated\n",
    "# df_test.sort_values(by='estimated',ascending=False)[['user_id','movie_id']].to_csv('baseline_submision.csv',index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv(\"/kaggle/output/training.csvbaseline_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt = testPred.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-08T17:59:19.360644Z",
     "start_time": "2021-04-08T17:59:19.267235Z"
    }
   },
   "outputs": [],
   "source": [
    "df_test[\"estimated\"] = testPred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-08T17:59:20.438549Z",
     "start_time": "2021-04-08T17:59:19.361542Z"
    }
   },
   "outputs": [],
   "source": [
    "df_test.sort_values(by='estimated',ascending=False)[['user_id','movie_id']].to_csv('Origi.csv',index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-08T17:59:20.454554Z",
     "start_time": "2021-04-08T17:59:20.439552Z"
    }
   },
   "outputs": [],
   "source": [
    "def dcg_at_k(y_true, y_score, k = 10):\n",
    "    \"\"\"\n",
    "    Discounted cumulative gain (DCG) at rank k\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    y_true : array-like, shape = [n_samples]\n",
    "        Ground truth (true relevance labels)\n",
    "    \n",
    "    y_score : array-like, shape = [n_samples]\n",
    "        Predicted scores\n",
    "    \n",
    "    k : int\n",
    "        Rank\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dcg : float\n",
    "    \"\"\"\n",
    "    order = np.argsort(y_score)[::-1]\n",
    "    print(order)\n",
    "    y_true = np.take(y_true, order[:k])\n",
    "    print(y_true)\n",
    "    gains = 2 ** y_true - 1\n",
    "    print(gains)\n",
    "    discounts = np.log2(np.arange(2, gains.size + 2))\n",
    "    print(discounts)\n",
    "    dcg = np.sum(gains / discounts)\n",
    "    \n",
    "    return dcg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-08T17:59:20.484549Z",
     "start_time": "2021-04-08T17:59:20.455551Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 4418  1793 10673 ...   650  3120  9974]\n",
      "187529    5.0\n",
      "379630    3.5\n",
      "255484    4.0\n",
      "422085    2.0\n",
      "37021     4.0\n",
      "Name: rating, dtype: float64\n",
      "187529    31.000000\n",
      "379630    10.313708\n",
      "255484    15.000000\n",
      "422085     3.000000\n",
      "37021     15.000000\n",
      "Name: rating, dtype: float64\n",
      "[1.         1.5849625  2.         2.32192809 2.5849625 ]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "52.10204734441061"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dcg_at_k(y_val,y_pred,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-08T20:30:58.103690Z",
     "start_time": "2021-04-08T20:30:58.091660Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.47707618490635173"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(0.22760168620479948)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-08T21:25:07.682647Z",
     "start_time": "2021-04-08T21:25:07.667682Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 4418  1793 10673 ...   650  3120  9974]\n",
      "187529    5.0\n",
      "379630    3.5\n",
      "255484    4.0\n",
      "422085    2.0\n",
      "37021     4.0\n",
      "201589    4.5\n",
      "409227    4.0\n",
      "776953    5.0\n",
      "818550    4.5\n",
      "14433     5.0\n",
      "Name: rating, dtype: float64\n",
      "187529    31.000000\n",
      "379630    10.313708\n",
      "255484    15.000000\n",
      "422085     3.000000\n",
      "37021     15.000000\n",
      "201589    21.627417\n",
      "409227    15.000000\n",
      "776953    31.000000\n",
      "818550    21.627417\n",
      "14433     31.000000\n",
      "Name: rating, dtype: float64\n",
      "[1.         1.5849625  2.         2.32192809 2.5849625  2.80735492\n",
      " 3.         3.169925   3.32192809 3.45943162]\n",
      "126327        0\n",
      "741775     8493\n",
      "803596     8515\n",
      "87068      3469\n",
      "290860     3477\n",
      "          ...  \n",
      "614894    10560\n",
      "560611    10313\n",
      "513558     9388\n",
      "49717      1139\n",
      "148657     5169\n",
      "Name: rating, Length: 10986, dtype: int64\n",
      "148657    5.0\n",
      "358020    5.0\n",
      "518762    5.0\n",
      "757545    5.0\n",
      "133488    5.0\n",
      "188295    5.0\n",
      "645030    5.0\n",
      "169487    5.0\n",
      "531096    5.0\n",
      "920924    5.0\n",
      "Name: rating, dtype: float64\n",
      "148657    31.0\n",
      "358020    31.0\n",
      "518762    31.0\n",
      "757545    31.0\n",
      "133488    31.0\n",
      "188295    31.0\n",
      "645030    31.0\n",
      "169487    31.0\n",
      "531096    31.0\n",
      "920924    31.0\n",
      "Name: rating, dtype: float64\n",
      "[1.         1.5849625  2.         2.32192809 2.5849625  2.80735492\n",
      " 3.         3.169925   3.32192809 3.45943162]\n",
      "NDCG of Validation: 0.6393794370039045\n"
     ]
    }
   ],
   "source": [
    "ndcgTrain = dcg_at_k(y_val,y_pred,10)\n",
    "possible = dcg_at_k(y_val,y_val,10)\n",
    "print('NDCG of Validation:',ndcgTrain/possible)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
