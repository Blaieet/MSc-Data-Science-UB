{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Blai Ras Jimenez\n",
    "\n",
    "## Assignment 2: Factorization Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-09T10:55:30.645709Z",
     "start_time": "2021-04-09T10:55:30.628711Z"
    },
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kaggle/input\\movielens-fds\\movielens-fds.zip\n",
      "kaggle/input\\movielens-fds\\sample_submission.csv\n",
      "kaggle/input\\movielens-fds\\test.csv\n",
      "kaggle/input\\movielens-fds\\training.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pylab as plt\n",
    "import time\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-09T10:55:31.025530Z",
     "start_time": "2021-04-09T10:55:31.010530Z"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate(predict_f,data_test):\n",
    "    \"\"\" RMSE-based predictive performance evaluation with pandas. \"\"\"\n",
    "    ids_to_estimate = zip(data_test.user_id, data_test.movie_id)\n",
    "    estimated = np.array([predict_f(u,i) for (u,i) in ids_to_estimate ])\n",
    "    real = data_test.rating.values\n",
    "    return compute_rmse(estimated, real)\n",
    "\n",
    "\n",
    "def compute_rmse(y_pred, y_true):\n",
    "    \"\"\" Compute Root Mean Squared Error. \"\"\"\n",
    "    return np.sqrt(np.mean(np.power(y_pred - y_true, 2)))\n",
    "\n",
    "\n",
    "## Divide the data in two sets: training and test\n",
    "def assign_to_set(df):\n",
    "    sampled_ids = np.random.choice(df.index,\n",
    "                                   size=np.int64(np.ceil(df.index.size * 0.05)),\n",
    "                                   replace=False)\n",
    "    df['for_testing'] = False\n",
    "    df.loc[sampled_ids, 'for_testing'] = True\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-09T10:55:31.228856Z",
     "start_time": "2021-04-09T10:55:31.223856Z"
    }
   },
   "outputs": [],
   "source": [
    "# Discount Cumulative Gain function\n",
    "def ndcg(y_pred, y_true,k):\n",
    "    \n",
    "    # First sort my predicted scores\n",
    "    sort = np.argsort(y_pred)[::-1]\n",
    "    \n",
    "    # Take k elements of my array\n",
    "    y_true = np.take(y_true, sort[:k])\n",
    "    \n",
    "    # Compute the G: gains\n",
    "    G = 2 ** y_true - 1\n",
    "    \n",
    "    # Compute the D: discounts\n",
    "    D = np.log2(np.arange(2, G.size + 2))\n",
    "    \n",
    "    # Finally compute the DCG\n",
    "    dcg = np.sum(G/D)\n",
    "    \n",
    "    return dcg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-09T10:55:45.100098Z",
     "start_time": "2021-04-09T10:55:44.524828Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('kaggle/input/movielens-fds/training.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-09T10:55:45.116049Z",
     "start_time": "2021-04-09T10:55:45.101999Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(945180, 5)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-09T10:55:45.227108Z",
     "start_time": "2021-04-09T10:55:45.164000Z"
    }
   },
   "outputs": [],
   "source": [
    "# If you wish to do an small, quick train, re-sample the original dataset with less ratings.\n",
    "df = df.sample(100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-09T10:55:46.255068Z",
     "start_time": "2021-04-09T10:55:45.676960Z"
    }
   },
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('kaggle/input/movielens-fds/test.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-09T08:25:21.465940Z",
     "start_time": "2021-04-09T08:25:21.451978Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(848600, 4)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature encoding\n",
    "\n",
    "I tried two different latent vectors (features) for my Factorization Machine approach: the genre and the releasing year of the movie.\n",
    "\n",
    "### Genre\n",
    "\n",
    "In order to encode this feature inside my recommender system I decided to categorize it using a one-hot encoding philosophy: multiple binary variables (dummy variables). \n",
    "\n",
    "The tricky part was slicing the \"genre\" column, encoded with the character \" | \" as separator. The way I dealt with this problem is using the sklearn Multi Label Binarizer. \n",
    "\n",
    "First, I get each genre of each movie splitting its text by \"|\". Then, I pass this Pandas series to the MLB, which is able to create multiple binary variables with indexing using its method $\\texttt{fit_transform}$. Therefore, it's easy to create a Pandas dataframe containing each dummy variable from it. \n",
    "\n",
    "At this point, all that's left is joining this one-hot encoding dataframe to the original dataframe. As a consequence, we can drop the genre original column and the one we created when slicing.\n",
    "\n",
    "There are movies with no genre listed. I decided to keep them under the column \"(no genres listed)\". There are also movies with the genre \"IMAX\" which is not really a \"genre\", but I keep them either way.\n",
    "\n",
    "I've implemented this approach in the function below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-09T10:55:46.726611Z",
     "start_time": "2021-04-09T10:55:46.707612Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "def genre_categorical(df):\n",
    "    \n",
    "    df['gen_list'] = df['genre'].str.split('|')\n",
    "\n",
    "    ## Column containing a genre list for each movie\n",
    "    serieList = pd.Series(df[\"gen_list\"])\n",
    "\n",
    "    mlb = MultiLabelBinarizer()\n",
    "\n",
    "    # Create a new dataframe of the genres from the list for each row \n",
    "    one_hot_genres = pd.DataFrame(mlb.fit_transform(serieList),columns=mlb.classes_,index=serieList.index)\n",
    "    \n",
    "    # Removing unwanted columns\n",
    "    df = df.drop([\"gen_list\",\"title\",\"genre\"],axis=1)\n",
    "    \n",
    "    # Merging\n",
    "    return pd.merge(df,one_hot_genres, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Year\n",
    "\n",
    "I also tried to aisle the year of each movie and work with it as a feature. The way the year is encoded is as text next to the movie title. Therefore, I used regex to extract it and save it to a new column, \"year\". \n",
    "\n",
    "In order to deal with the movies that have no year registered, I transform the type of this \"year\" column to datetime, getting \"NaN's\" when the year is invalid. I replaced this NaN's with the mean year of the overall movies.\n",
    "\n",
    "As a result, I get a lot of different years. It's not a good idea to binary categorize each year, because as a result I would get like 40 different columns if we count the binarized genres.\n",
    "\n",
    "Therefore, I splitted this \"year\" column into 3 new ones by its quantiles: \"year_old\" contains all the years from the oldest to the 0.25 quantile, \"year_mid\" from 0.25 to 0.75, and \"year_new\" from 0.75 to the newest year. \n",
    "In order to binarize it I just use the $\\texttt{pd.get_dummies}$ Pandas method.\n",
    "\n",
    "I coded this transformation in the function below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-09T10:55:47.008810Z",
     "start_time": "2021-04-09T10:55:46.993780Z"
    }
   },
   "outputs": [],
   "source": [
    "def categorical_year(df):\n",
    "    # Year regex extraction\n",
    "    df['year'] = df.title.str.extract(\"\\((\\d{4})\\)\", expand=True)\n",
    "    # Year to Year datatime in order to get NaN's\n",
    "    df.year = pd.to_datetime(df.year, format='%Y')\n",
    "    df.year = df.year.dt.year\n",
    "    \n",
    "    # Replace NaN's with the overall mean\n",
    "    df[\"year\"] = df[\"year\"].fillna(int(np.nanmean(df.year.unique())))\n",
    "    \n",
    "    # Year into 3-way categorization by quantiles\n",
    "    df['year'] = pd.cut(df.year,\n",
    "                     bins=[df.year.quantile(0), df.year.quantile(0.25), df.year.quantile(0.75), df.year.quantile(1)],\n",
    "                     labels=[\"old\", \"mid\", \"new\"])\n",
    "    # Year binarization\n",
    "    return pd.get_dummies(df,columns=[\"year\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nevertheless, after various tests with this year one-hot encoding, **I decided not to add this feature**, due to poor performance in terms of RMSE. Probably, there are too many columns (25) if we categorize the genre and the year, and the model starts to overfit, as we can see below (k=10, lambda=0.03, lr=0.01, 60 iterations):\n",
    "\n",
    "<img src=\"TrainWithYearPlot.PNG\">\n",
    "\n",
    "In consequence, I decided to only add the genre as feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-09T10:55:50.049013Z",
     "start_time": "2021-04-09T10:55:47.258550Z"
    }
   },
   "outputs": [],
   "source": [
    "# Transform my datasets with this genre one-hot encoding\n",
    "df = genre_categorical(df)\n",
    "df_test = genre_categorical(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-09T10:55:50.080953Z",
     "start_time": "2021-04-09T10:55:50.050979Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>(no genres listed)</th>\n",
       "      <th>Action</th>\n",
       "      <th>Adventure</th>\n",
       "      <th>Animation</th>\n",
       "      <th>Children</th>\n",
       "      <th>Comedy</th>\n",
       "      <th>Crime</th>\n",
       "      <th>Documentary</th>\n",
       "      <th>...</th>\n",
       "      <th>Film-Noir</th>\n",
       "      <th>Horror</th>\n",
       "      <th>IMAX</th>\n",
       "      <th>Musical</th>\n",
       "      <th>Mystery</th>\n",
       "      <th>Romance</th>\n",
       "      <th>Sci-Fi</th>\n",
       "      <th>Thriller</th>\n",
       "      <th>War</th>\n",
       "      <th>Western</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1762</td>\n",
       "      <td>307</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1762</td>\n",
       "      <td>67534</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1762</td>\n",
       "      <td>2317</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1762</td>\n",
       "      <td>94011</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1762</td>\n",
       "      <td>164725</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  movie_id  (no genres listed)  Action  Adventure  Animation  \\\n",
       "0     1762       307                   0       0          0          0   \n",
       "1     1762     67534                   0       0          0          0   \n",
       "2     1762      2317                   0       0          0          0   \n",
       "3     1762     94011                   0       1          0          0   \n",
       "4     1762    164725                   0       0          0          0   \n",
       "\n",
       "   Children  Comedy  Crime  Documentary  ...  Film-Noir  Horror  IMAX  \\\n",
       "0         0       0      0            0  ...          0       0     0   \n",
       "1         0       1      0            0  ...          0       0     0   \n",
       "2         0       1      0            0  ...          0       0     0   \n",
       "3         0       0      0            0  ...          0       0     0   \n",
       "4         1       1      0            0  ...          0       0     0   \n",
       "\n",
       "   Musical  Mystery  Romance  Sci-Fi  Thriller  War  Western  \n",
       "0        0        0        0       0         0    0        0  \n",
       "1        0        0        0       0         0    0        0  \n",
       "2        0        0        0       0         0    0        0  \n",
       "3        0        0        0       0         1    0        0  \n",
       "4        0        0        0       0         0    0        0  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data treatment\n",
    "\n",
    "This function below splits my dataframe into test/validation sets and also changes the column data type for \"user_id\" and \"movie_id\" so the model do not treat them as integers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-09T10:55:50.096987Z",
     "start_time": "2021-04-09T10:55:50.083977Z"
    }
   },
   "outputs": [],
   "source": [
    "def data_split(df,df_test):\n",
    "    grouped = df.groupby('user_id', group_keys=False).apply(assign_to_set)\n",
    "    df_train = df[grouped.for_testing == False]\n",
    "    df_val   = df[grouped.for_testing == True]\n",
    "    \n",
    "    val = df_val.copy()\n",
    "    train = df_train.copy()\n",
    "    test = df_test.copy()\n",
    "    \n",
    "    y_train = train['rating']\n",
    "    train.drop(['rating'], axis=1, inplace=True)\n",
    "\n",
    "    train['user_id'] = train['user_id'].astype('str')\n",
    "    train['movie_id'] = train['movie_id'].astype('str')\n",
    "\n",
    "    y_val = val[\"rating\"]\n",
    "    val.drop(['rating'], axis=1, inplace=True)\n",
    "    val['user_id'] = val['user_id'].astype('str')\n",
    "    val['movie_id'] = val['movie_id'].astype('str')\n",
    "\n",
    "    test['user_id'] = test['user_id'].astype('str')\n",
    "    test['movie_id'] = test['movie_id'].astype('str')\n",
    "    \n",
    "    return train,y_train,val,y_val,test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-09T10:56:00.284186Z",
     "start_time": "2021-04-09T10:55:50.097955Z"
    }
   },
   "outputs": [],
   "source": [
    "train,y_train,val,y_val,test = data_split(df,df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-09T10:56:00.300195Z",
     "start_time": "2021-04-09T10:56:00.286187Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: (88984, 22) \n",
      "Val size: (11016, 22) \n",
      "Test size: (848600, 22)\n"
     ]
    }
   ],
   "source": [
    "print(\"Train size:\",train.shape,\n",
    "      \"\\nVal size:\",val.shape,\n",
    "      \"\\nTest size:\",test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "\n",
    "Below is the modified base code in order to perform the Factorization Machine model. Long story short, I changed the way we index each movie/user with the $\\texttt{getIdx}$ function and I perform the training inside the $\\texttt{sgd}$ function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-09T10:56:04.439452Z",
     "start_time": "2021-04-09T10:56:04.411421Z"
    }
   },
   "outputs": [],
   "source": [
    "from scipy import sparse\n",
    "\n",
    "class RecSys_FM():\n",
    "    \"\"\" Collaborative filtering using a custom sim(u,u'). \"\"\"\n",
    "\n",
    "    def __init__(self,df_train,df_val,num_components=10,k=10):\n",
    "        \"\"\" Constructor \"\"\"\n",
    "        self.df_train = df_train\n",
    "        self.df_val = df_val\n",
    "        self.num_components=num_components\n",
    "        self.k = k\n",
    "        # We create a dictionary where we will store the user_id and movie_id which correspond \n",
    "        # to each index in the Rating matrix\n",
    "        \n",
    "        i = 0\n",
    "        cols = {}\n",
    "        for col in df_train.columns:\n",
    "            cols[col] = i\n",
    "            i += 1\n",
    "\n",
    "        idxs = {}\n",
    "        nonZero = 0\n",
    "        for col in df_train.columns:\n",
    "            if col == \"user_id\" or col == \"movie_id\":\n",
    "                idxs[cols[col]] = {}\n",
    "                colset = set(df_train[col])\n",
    "                for movieUserCol in colset:\n",
    "                    idxs[cols[col]][movieUserCol] = nonZero\n",
    "                    nonZero += 1\n",
    "            else:\n",
    "                idxs[cols[col]] = nonZero\n",
    "                nonZero += 1\n",
    "        self.idxs = idxs\n",
    "        self.nonZero = nonZero\n",
    "        \n",
    "        # initialize latent vectors\n",
    "        self.w0 = np.mean(df_val)\n",
    "        self.w1 = np.zeros(self.nonZero)\n",
    "        self.v = np.random.normal(scale=0.1,size=(self.nonZero, self.k))\n",
    "        \n",
    "        \n",
    "    def getIdx(self, vec):\n",
    "        idx = []\n",
    "        for col in range(len(vec)):\n",
    "            if isinstance(self.idxs[col], int) or isinstance(self.idxs[col], float):\n",
    "                idx.append((self.idxs[col], vec[col]))\n",
    "            else:\n",
    "                try:\n",
    "                    idx.append((self.idxs[col][vec[col]], 1.))\n",
    "                except:\n",
    "                    idx.append((0., 0.))\n",
    "        return idx\n",
    "        \n",
    "    def __sdg__(self):\n",
    "        df_train = np.array(self.df_train)\n",
    "        df_val = np.array(self.df_val)\n",
    "        learning_rate = self.learning_rate\n",
    "        lmbda = self.lmbda\n",
    "        w0 = self.w0\n",
    "        w1 = self.w1\n",
    "        v = self.v\n",
    "        nonZero = self.nonZero\n",
    "\n",
    "        m = df_train.shape[0]\n",
    "        n = df_train.shape[1]\n",
    "        \n",
    "        #SGD\n",
    "        for epoch in range(self.n_epochs):\n",
    "            start_time = time.perf_counter()\n",
    "            \n",
    "            predictions = []\n",
    "            for i in range(m):\n",
    "                x = df_train[i, :]\n",
    "                tempVals = self.getIdx(x)\n",
    "                idx = {}\n",
    "                firstSum = 0\n",
    "                secondSum = 0\n",
    "                thirdSum = np.zeros(self.k)\n",
    "\n",
    "                for col in range(n):\n",
    "                    index, value = tempVals[col]\n",
    "                    idx[index] = value\n",
    "                    firstSum += w1[index] * value\n",
    "\n",
    "                for j in range(self.k):\n",
    "                    jSum1 = 0.0\n",
    "                    jSum2 = 0.0\n",
    "                    for col in range(n):\n",
    "                        index, value = tempVals[col]\n",
    "                        tmp = v[index, j] * value\n",
    "                        jSum1 += tmp\n",
    "                        jSum2 += tmp * tmp\n",
    "                    thirdSum[j] = jSum1\n",
    "                    secondSum += jSum1 * jSum1 - jSum2\n",
    "\n",
    "                yhat = w0 + firstSum + 0.5 * secondSum\n",
    "                yhat = max(1., yhat)\n",
    "                yhat = min(5., yhat)\n",
    "                out = (yhat - df_val[i])\n",
    "\n",
    "                #Update Rule w0\n",
    "                w0 = w0 - (learning_rate * out) - learning_rate * w0 * lmbda\n",
    "\n",
    "                for col in range(n):\n",
    "                    index, value = tempVals[col]\n",
    "                    tmp = learning_rate * value * out\n",
    "                    w1[index] -= (tmp + (learning_rate*lmbda)*w1[index])\n",
    "                    for j in range(self.k):\n",
    "                        v[index, j] -= (tmp * (thirdSum[j] - v[index, j] * value) + (learning_rate*lmbda)*v[index, j])\n",
    "            \n",
    "            self.train_rmse.append(compute_rmse(yhat,df_val))\n",
    "            self.test_rmse.append(compute_rmse(yhat,self.y_val))\n",
    "            \n",
    "            print(\"Epoch\",epoch,\"lasted:\",time.perf_counter()-start_time)\n",
    "            print('\\tTrain RMSE: %s' % self.train_rmse[-1])\n",
    "            print('\\tTest RMSE: %s' % self.test_rmse[-1])\n",
    "\n",
    "        self.w0 = w0\n",
    "        self.w1 = w1\n",
    "        self.v = v\n",
    "                                      \n",
    "        if(self.verbose):\n",
    "            self.__plot_learning_curves__()\n",
    "        \n",
    "    def fit(self,y_val,n_epochs = 10,learning_rate =0.001,lmbda=0.1,verbose =True):\n",
    "        \"\"\" We decompose the R matrix into to submatrices using the training data \"\"\"\n",
    "        self.verbose = verbose\n",
    "        self.learning_rate = learning_rate\n",
    "        self.lmbda = lmbda\n",
    "        self.y_val = y_val\n",
    "        self.n_epochs = n_epochs\n",
    "        self.train_rmse =[]\n",
    "        self.test_rmse = []\n",
    "        \n",
    "        self.__sdg__()\n",
    "        return\n",
    "    \n",
    "    def __plot_learning_curves__(self):\n",
    "        plt.plot(self.train_rmse,'--o',label=\"train_error\")\n",
    "        plt.plot(self.test_rmse,'--o',label=\"test_error\")\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "        \n",
    "    def predict(self, df, verbose=True):\n",
    "\n",
    "        df = np.array(df)\n",
    "        \n",
    "        w0 = self.w0\n",
    "        w1 = self.w1\n",
    "        v = self.v\n",
    "        nonZero = self.nonZero\n",
    "\n",
    "        m = df.shape[0]\n",
    "        n = df.shape[1]\n",
    "        \n",
    "        predictions = []\n",
    "        for i in range(m):\n",
    "            x = df[i, :]\n",
    "            tempVals = self.getIdx(x)\n",
    "            idx = {}\n",
    "            firstSum = 0\n",
    "            secondSum = 0\n",
    "            thirdSum = np.zeros(self.k)\n",
    "\n",
    "            for col in range(n):\n",
    "                index, value = tempVals[col]\n",
    "                idx[index] = value\n",
    "                index = int(index)\n",
    "                firstSum += w1[index] * value\n",
    "\n",
    "            for j in range(self.k):\n",
    "                jSum1 = 0\n",
    "                jSum2 = 0\n",
    "                for col in range(n):\n",
    "                    index, value = tempVals[col]\n",
    "                    index = int(index)\n",
    "                    tmp = v[index, j] * value\n",
    "                    jSum1 += tmp\n",
    "                    jSum2 += tmp * tmp\n",
    "                thirdSum[j] = jSum1\n",
    "                secondSum += jSum1 * jSum1 - jSum2\n",
    "\n",
    "            yhat = w0 + firstSum + 0.5 * secondSum\n",
    "            yhat = max(1., yhat)\n",
    "            yhat = min(5., yhat)\n",
    "            predictions.append(yhat)\n",
    "\n",
    "        return predictions\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-09T11:27:44.988433Z",
     "start_time": "2021-04-09T11:19:24.971539Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 lasted: 50.78183259999969\n",
      "\tTrain RMSE: 1.256138521470077\n",
      "\tTest RMSE: 1.2469393908181268\n",
      "Epoch 1 lasted: 49.8561138999994\n",
      "\tTrain RMSE: 1.2922196725917083\n",
      "\tTest RMSE: 1.27945814289381\n",
      "Epoch 2 lasted: 49.421002600000065\n",
      "\tTrain RMSE: 1.250929302854489\n",
      "\tTest RMSE: 1.2422839402487964\n",
      "Epoch 3 lasted: 51.11197979999997\n",
      "\tTrain RMSE: 1.189462644369291\n",
      "\tTest RMSE: 1.188335396016673\n",
      "Epoch 4 lasted: 51.51828690000002\n",
      "\tTrain RMSE: 1.1508256556399155\n",
      "\tTest RMSE: 1.1557449548411467\n",
      "Epoch 5 lasted: 50.379704400000264\n",
      "\tTrain RMSE: 1.1242775923938868\n",
      "\tTest RMSE: 1.1343614536513607\n",
      "Epoch 6 lasted: 48.76578840000002\n",
      "\tTrain RMSE: 1.1028751867893418\n",
      "\tTest RMSE: 1.118177359099356\n",
      "Epoch 7 lasted: 48.76347859999987\n",
      "\tTrain RMSE: 1.0879856211141123\n",
      "\tTest RMSE: 1.1079813339017468\n",
      "Epoch 8 lasted: 49.46762269999999\n",
      "\tTrain RMSE: 1.0788139619152257\n",
      "\tTest RMSE: 1.1026353532477322\n",
      "Epoch 9 lasted: 49.765323499999795\n",
      "\tTrain RMSE: 1.0737578404491834\n",
      "\tTest RMSE: 1.10039777566761\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD5CAYAAAAp8/5SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3dd3xUVf74/9eZyYQ00kNLKKGFEqpAgqCAIIgFYkFFULGh2HBXWeXz84eK7qqLuooNkaUoCqIUC64gSpPeeweBJGgKJqS3Od8/bgIJmTRSbjJ5Px+PPDJz75173xnlPWfOOfd9lNYaIYQQzstidgBCCCGqlyR6IYRwcpLohRDCyUmiF0IIJyeJXgghnJwkeiGEcHIuZR2glJoN3AzEaa3DHewfCbwK2IFc4Bmt9W/5+24A3gOswCyt9RvlCSowMFC3atWqvH+DEELUezt27EjQWgc52qfKmkevlLoWSAU+KyHRewFpWmutlOoKLNJad1BKWYGjwPVANLANGK21PlhWwL169dLbt28v6zAhhBD5lFI7tNa9HO0rs+tGa70OOF/K/lR96dPCEyh43Ac4rrU+qbXOBhYCIysUuRBCiEqrkj56pdStSqnDwHLgwfzNwcDZQodF528r6RzjlVLblVLb4+PjqyIsIYQQVFGi11ov1Vp3AKIw+usBlKNDSznHTK11L611r6Agh91MQgghrkCZg7EVobVep5Rqo5QKxGjBNy+0OwSIrcrrCSFqp5ycHKKjo8nMzDQ7FKfj5uZGSEgINput3K+pdKJXSrUFTuQPxvYEXIFEIAlop5QKBWKAu4F7Kns9IUTtFx0dTcOGDWnVqhVKOfpyL66E1prExESio6MJDQ0t9+vKM71yATAQCFRKRQMvAbb8i84AbgfuU0rlABnAXfmDs7lKqSeBFRjTK2drrQ9U7M+qe5btimHaiiPEJmXQzNedScPCiOpR4tCEEE4pMzNTknw1UEoREBBARccxy0z0WuvRZex/E3izhH0/Aj9WKKI6bNmuGCYv2UdGTh4AMUkZTF6yD0CSvah3JMlXjyt5X+XO2Co0bcWRi0m+QEZOHtNWHDEpIiGEkERfpWKTMiq0XQghaoIk+iqSnp2Lq4vjt7OZr3sNRyNE3bJsVwz93viV0BeW0++NX1m2K6ZS50tKSuKjjz6q8OtuvPFGkpKSKnXt2kgSfRVIycxh3OxtZOXasVmL9p9ZFTx3fXuTIhOi9isY24pJykBzaWyrMsm+pESfl5fn4OhLfvzxR3x9fa/4uqXJzc0t9Xl5X3clqnQefX2UnJ7D/XO2si8mmfdH9yDPri/Oumno5sKFzFx2RycR1TNYBqdEvXXXJ5uKbbu5a1Pu7duKf/902OHY1svfHyCqRzDn07KZMH9Hkf1fPdq31Ou98MILnDhxgu7du2Oz2fDy8qJp06bs3r2bgwcPEhUVxdmzZ8nMzGTixImMHz8egFatWrF9+3ZSU1MZPnw4/fv3Z+PGjQQHB/Ptt9/i7u742/mJEyd44okniI+Px8PDg08//ZQOHTowbtw4/P392bVrFz179iQxMbHI83vvvZfHHnuM9PR02rRpw+zZs/Hz82PgwIFcffXVbNiwgREjRvDss89W5O0uRhJ9JeTk2Rn73y0c/uMCH43pybDOTYCiM2z+ufwgX245w8PXtKa5v4dZoQpRa51LdnxTVVJ6zhWf84033mD//v3s3r2bNWvWcNNNN7F///6Lc89nz56Nv78/GRkZ9O7dm9tvv52AgIAi5zh27BgLFizg008/5c4772Tx4sWMHTvW4fXGjx/PjBkzaNeuHVu2bOHxxx/n119/BeDo0aOsWrUKq9XKuHHjijzv2rUr77//PgMGDGDKlCm88sorvPvuu8bfn5TE2rVrr/g9KEwSfSXYrBZG92lBU183BoU1cnjM5OEdGRvZUpK8qNdKa4E383UnxsGEheD8sS1/T9cyW/Bl6dOnT5EbjKZPn87SpUsBOHv2LMeOHSuW6ENDQ+nevTsAV111Fb///rvDc6emprJx40ZGjRp1cVtWVtbFx6NGjcJqtRZ7npycTFJSEgMGDADg/vvvL3KOu+666wr/2uIk0V+Bc8kZnE5MJ7J1APdEtCj1WItF0TLAE4A5G04R4ufB9Z0a10SYQtQJk4aFFbn/BMDdZmXSsLAqu4anp+fFx2vWrGHVqlVs2rQJDw8PBg4c6LBUQ4MGDS4+tlqtZGQ4nj1nt9vx9fVl9+7dZV7b0fPyxFxZMhhbQWfPp3PnJ5t4asEuMnNKH9gpLDvXzrJdMTz55U62/15i1Wch6p2oHsG8flsXgn3dURgt+ddv61KpmwwbNmxISkqKw33Jycn4+fnh4eHB4cOH2bx58xVfB8Db25vQ0FC+/vprwChTsGfPnjJf5+Pjg5+fH+vXrwfg888/v9i6r2rSoq+AUwlpjPl0M2nZeXz2YB/cbNayX5TP1cXC7HG9uWPGJh6at52vH+tL+8YNqzFaIeqOqB7BVXr3eEBAAP369SM8PBx3d3caN770LfqGG25gxowZdO3albCwMCIjIyt9vS+++IIJEybw2muvkZOTw9133023bt3KfN28efMuDsa2bt2aOXPmVDoWR8pcYcoMtXGFqWN/pjBm1hZy7Zr5D0XQqZm34wP3LoJfpkJyNPiEwOAp0PXOi7vPnk/n9o83YrUoFk+4WubYC6d06NAhOnbsaHYYTsvR+1upFaaEYeG2s2jgq/GRpSf575+G5LOANn5//7SxPV9zfw/mPdiHtKxcNp1IrJHYhRD1m3TdlMFu11gsiv+7sSMPXxNKU59SWuC/TIWcywZscjKM7YVa9R2berN20iD8PF2rKWohRHV44okn2LBhQ5FtEydO5IEHHjApovKRRF+KHafPM+XbA8y6vxdNfdxLT/KQ35J3tD262KaCJL/xeAILt53l7Tu7YbPKFywharMPP/zQ7BCuiGSWEmw6kci9/91KenY5ZtZoDatfL3m/T0iJu04lpvHdnlgmL9lHbRwvEULUfZLoHVh7NJ5xc7YS4ufOV49Glt2S3/QBrH0DWlwNNgfHhl5b4kvHRLRk4uB2fLMjmn9LOWMhRDWQrpvLbDiewCPzttO2kRfzH47Avzz96D3uBRc36P0w7Pu60KybYHD3h91fQHBPY78DzwxpR3xqFh+vOUGQVwMe7F/+JcKEEKIs0qK/TOdm3ozs3owFj0SWnuSTzsC3T0BOJrj7Qp9HQClj0PVv++HlJPjbAXh4FbQfDsufha2fOjyVUopXR4YzrHNjDp67IF04QlTSlZYpBnj33XdJT0+v4ojMJYk+37qj8WTm5OHr4cq0Ud3w8ShlhfXY3TBrCBz8HhKOln5ilwZw52cQdiPsXwx5jkuOWi2K90f3ZNodXVFKSbIX9cveRfCfcHjZ1/hdaErylagNif7ykshllUiu6HEVIYkeWLD1DPfP2cqMtSfKPvjoCphzI1hd4aEV0LRr2a9xcYVR82DMN2B1KTHZu7pYUEpx9nw6N7//G/uikyv4lwhRB5Xj/pOKKlymeNKkSUybNo3evXvTtWtXXnrpJQDS0tK46aab6NatG+Hh4Xz11VdMnz6d2NhYBg0axKBBg0o8/8qVK+nbty89e/Zk1KhRpKamAkaZ46lTp9K/f3++/vrrYs8XLFhAly5dCA8P5/nnn794Pi8vL6ZMmUJERASbNhUv6VxZ9b6Pfu6GU7z8/UEGhQXx2IA2pR+8dxEsfRSadIF7FkHDJuW/kIur8ZOdBl/cCR1vgcjHHB7q6mIhKT2HcXO28s2EqwkNrLriRkKYYs5Nxbd1jjK6PFe94vj+k/89b3SFpiXCovuK7n9geamXK1ymeOXKlXzzzTds3boVrTUjRoxg3bp1xMfH06xZM5YvN86VnJyMj48P77zzDqtXryYwMNDhuRMSEnjttddYtWoVnp6evPnmm7zzzjtMmTIFADc3N3777TfA+MApeB4bG0tkZCQ7duzAz8+PoUOHsmzZMqKiokhLSyM8PJypU6eW482suHrdop+x9gQvf3+QoZ0aM+Peq8quXdOsB3QZBeN+rFiSL8zqCh5+8NPzsMnxV8vG3m58/lAfNHDf7C3EpTiu1y2EU7hQwkpSGVVT/G/lypWsXLmSHj160LNnTw4fPsyxY8fo0qULq1at4vnnn2f9+vX4+PiU63ybN2/m4MGD9OvXj+7duzNv3jxOnz59cf/l5YULnm/bto2BAwcSFBSEi4sLY8aMYd26dYBRHfP222+vkr/XkXrbok9IzWLG2hPc0q0Z75R2s1JOJuxdCD3vh8B2cNvMyl3YaoM75sA3D8KKyYCGvk8UO6x1kBezx/Vm9MzN3D97G189Gom3WynjBkLUZqW1wH1CHN9s6NPc+O0ZUGYLvjRaayZPnsyjjz5abN+OHTv48ccfmTx5MkOHDr3YKi/rfNdffz0LFixwuL+kssSljbu5ubkVqVlf1epdi15rjdaaQK8GLHu8H+/e1b3kJJ+WCJ+NgO8nQnQVFlmz2uCO2dBpJKz4P9g2y+Fh3Zv78vHYnni6WsnNk8FZ4aQGTyl+/4nN3dh+hQqXKR42bBizZ8++2I8eExNDXFwcsbGxeHh4MHbsWJ577jl27txZ7LWOREZGsmHDBo4fPw5Aeno6R4+WMSkDiIiIYO3atSQkJJCXl8eCBQuqrSzx5epVi15rzdQfDuLn4crTg9vRqrS+78QT8MUdkBwDo+ZC895VG4zVBrf/FzyDoFXJN1QNDGvEgPZBKKXIzrVjtSisFll7VjiRgjpQpVR9rajCZYqHDx/OPffcQ9++xipVXl5ezJ8/n+PHjzNp0iQsFgs2m42PP/4YMJYFHD58OE2bNmX16tXFzh0UFMTcuXMZPXr0xZWkXnvtNdq3b19qTE2bNuX1119n0KBBaK258cYbGTly5BX/jRVRb8oU2+2aF7/dz5dbzvBAv1ZMublTyYt1n9kCC+42Ho9eCC0iqjQWh7SG39eXeBdtTp6dB+duIzTQk1dGdJaFxkWtJmWKq5eUKXYgz66Z9M1evtxyhgkD25Se5AGyLhgt7YdX1UySB+OO2nm3wG/vOtxts1ro1NSbzzad5sPVx2smJiGEU3D6rhutNc8u2s2y3bH8bUh7nh7c1nGS1xr+2GfMi293PbQeZMx5rymdb4OjP8Gql0Db4Zq/Fzvk+Rs6EJ+SxVsrjxLo1YC7+5S+Xq0QonIiIiKKLPQNxpJ/Xbp0MSmiK+P0iV4pRf92QXRo6l3yPHl7njFnd/t/4aGfIaRXzSZ5MK5360xAwS+vABquebbIIRaL4s07unI+PZv/W7oPf09Xhna+wmmeQogybdmyxewQqoTTJvrMnDwOxF7gqpZ+3HFVyWWCyU6Dbx6Co/+Dq5+GZj1rLsjLWV3g1k+Mmjmr/wUdRxhTOguxWS18NKYnExfuJsTPw6RAhSib1lrGkqrBlYyrOmUffXp2Lg/O3caYWZuJu1DKzUYpfxrlDI6tgBvfgqGvgsXkt6Qg2T/wU7EkX8DD1YVP7+t1cUnD82nZNRmhEGVyc3MjMTFRajZVMa01iYmJuLm5Veh1TtOiX7YrhmkrjhCblIHNaiE7z847d3ajkXcpb8jh/KJkdy+AsBtqLtiyWKyXpnMeWAaJx+Ha5xwe+sGvx/h882kWT7haWvii1ggJCSE6Opr4+HizQ3E6bm5uhISU0kvhgFMk+mW7Ypi8ZB8ZOUbVt+w8OzarwlLS18asVGjgBb0egnZDwbcWD2oeXwW7PjfGEQY+X2z3kE6N+WTdSe6bvZVvHru6fPXzhahmNpuN0FBZV6G2cIqum2krjlxM8gVy8jTTHK3YtGchvNcN4g4bfeG1OckD3PIedB8Da/4Fa94otrtDE29m3deL6L8yeHDuNtKzHVfGFELUX06R6GOTMsrerjWsedOoPtm405UXJatpFiuMeB+6j4U1rztcmzaidQDvj+7B3ugknvxyl/SLCiGKcIqum2a+7sQ4SPbNfPPrZ+Rmww/PGEv6dRsNt0w3SgbXFQXJHiAnzfjQuqxbaljnJvzr1i40dLPJTAchRBFlJnql1GzgZiBOax3uYP8YoKDzOBWYoLXek7/vdyAFyANyS7o9t7ImDQsr0kcP4G6zMmlYmPFky8dGkh/wAgx8oViSrBMsFiPZK2X8pMaDZ2CRv6XgBqplu2L414+HiE/JopmvO5OGhRHVI9isyIUQJitPi34u8AHwWQn7TwEDtNZ/KaWGAzOBwnUDBmmtEyoVZRkKkljBrJtiyS3iMQgMq10za65EwdTP5BiYORB63gfXvVgk2S/bFcPzi/eSlWsHICYpg8lL9gFIsheinioz0Wut1ymlWpWyf2Ohp5uBis37qSJRPYKLJrJze2Huo8Z6rR7+dT/JF9awKYQNh/VvARqu+/8vJvtpK45cTPIFMnLymLbiiCR6Ieqpqu6jfwj4X6HnGliplNLAJ1rrElftUEqNB8YDtGhxBTNh9i66VObUIwCyUozCZGkJRqJ3JhYL3PyukdzXv23Uxhn8EihVvoFpIUS9UmWJXik1CCPR9y+0uZ/WOlYp1Qj4WSl1WGu9ztHr8z8EZoJRprhCFy9YXLhg3cn0BEBBv4kQVHqN6DrLYoGb/gPKAr/9B/xawVXjyh6YFkLUO1UyvVIp1RWYBYzUWicWbNdax+b/jgOWAn2q4nrF/DK1+OLCaNg4vVouV2tYLHDj23DDm8ZathgD0+6XrX3rYlGXBqaFEPVOpRO9UqoFsAS4V2t9tNB2T6VUw4LHwFBgf2Wv51BydMW2OxOLBSIfA1dPyLxAVM6PvH5rOMG+7igg2NeNt0Z1k/55Ieqx8kyvXAAMBAKVUtHAS4ANQGs9A5gCBAAf5c/fLphG2RhYmr/NBfhSa/1TNfwNpSwubMq4sHl2zYcVk4lqu4KoBofBLRoahIB1Cj8fHIBnAytXtwk0O0ohRA1zjqUEL++jB2Nx4VumV2rdyTpHa/j8Njj5a9HNNnf+aZnAzy7XsuKZa3GzVd9q80IIczj/UoJd7zSSuk9zQBm/61uSB2MWTuKx4ptzMnjOZSGnE9OZsfaECYEJIczkFCUQACOp17fE7kgJ4xJuaecY0a0ZH605QVT3YFoFetZwYEIIszhHi15cUtK4hE8IL97UEVerhSnfHZDCZ0LUI5Lonc3gKcb4RGFWG1z3Io283Zhycydu6drUnNiEEKZwnq4bYSjovip8l3B6AlyIBeDO3s1NDE4IYQZJ9M6o8HiF1vD1/cZi422HQNOuAMzb+DtJ6TlMHOJ4XVohhPOQrhtnp5RRF8cjAJaMhxxjsfSDsRd4/9djHP0zxeQAhRDVTRJ9feDhDyM/gPhDsPo1AJ4f3gEvNxdeXLZfBmaFcHKS6OuLdtfDkJehi9Gl4+/pyvM3dGDrqfMs3RVjamhCiOolib4+6f+3i3302PO4q1dzujf35V8/HibzssXVhRDOQwZj6xutjfVzc7Ow3DqD12/rQlJ6jpRFEMKJSYu+vlHKWJBlzwI4+B0dm3rTt00AALl59jJeLISoiyTR10cDnoem3eH7iZDyJwAf/HqMOz/ZRJ5dBmaFcDaS6Osjqw1umwk56fDdU6A1IX4e7DyTxMJtZ8yOTghRxSTR11dBYcYsnNMb4fxJRnZvRmRrf/790xESU7PMjk4IUYUk0ddnfR6FJ7dCQBuUUrwWFU5aVi5v/O+w2ZEJIaqQJPr6zGIB72bGTJwDS2kb4M7D17Tm2z2x/JGcaXZ0QogqIolewKm18PU42PAuTw9uy08Tr6GJj5vZUQkhqogkegGhA6DzrbDmdTwSD9A6yAuAmKSMMl4ohKgLJNELY279Te+AR+DFwmcfrj7O0HfWSheOEE5AEr0wePhD1IcQfxh+mcotXZuRa9e8uvyg2ZEJISpJEr24pO0QGPACtL2OFgEePDGoLcv3nmPd0XizIxNCVIIkelHUoMlGwgfGXxNKaKAnL313gKxcKXomRF0liV44tvbfuP04kVdGdCY5I4fjcalmRySEuEJSvVI4Zs+F3fO5tt31rP/HzXg2kP9VhKirpEUvHLt2EjTrAT88g2d2Anl2zcoDf8hqVELUQZLohWNWG9w6E3Iy4NsnWbzjLOM/38HPB/80OzIhRAVJohclC2oP10+Fk6u5tel5who35JXvD5KenWt2ZEKICpBEL0rX+xGYsAlbSHdejQonJimDD349bnZUQogKkEQvSmexGC17oA8HGNWjCZ+uPymzcISoQyTRi/KJ3gHzbublgJ/pGuJLWpZ03whRV0iiF+UTchWE347nxmksHulOt+a+ZkckhCgnSfSi/G58y1hYfMmjpKam8M7KI1zIzDE7KiFEGSTRi/Lz8IeojyDhCBk/vcT7q4/zn5+Pmh2VEKIMkuhFxbS5Dvr/naA2VzEmogXzNv7Ogdhks6MSQpRCEr2ouCEvQY8xTBraAT8PV15cth+7Xe6YFaK2kkQvrpjP4QUsClnErjNJLNp+1uxwhBAlKDPRK6VmK6XilFL7S9g/Rim1N/9no1KqW6F9NyiljiiljiulXqjKwEUtcCGWNqcX8U74KXqH+psdjRCiBOVp0c8Fbihl/ylggNa6K/AqMBNAKWUFPgSGA52A0UqpTpWKVtQu1zwLzXpyW8xbtGmQYnY0QogSlJnotdbrgPOl7N+otf4r/+lmICT/cR/guNb6pNY6G1gIjKxkvKI2sdrgtpmQk0n2kglM+Hw7O07/VfbrhBA1qqr76B8C/pf/OBgo3HEbnb/NIaXUeKXUdqXU9vh4WbquzghsB0NfxfX31ejTG3lx2X5y8+xmRyWEKKTKEr1SahBGon++YJODw0qcmqG1nqm17qW17hUUFFRVYYma0PtheGgVI0aO4tC5C3y++bTZEQkhCqmSRK+U6grMAkZqrRPzN0cDzQsdFgLEVsX1RC2jFDTvzfDwJoxplcK7Kw8RdyHT7KiEEPkqneiVUi2AJcC9WuvCt0luA9oppUKVUq7A3cB3lb2eqL1U/BFe+/NxHrAv4T+r5I5ZIWqLMhcCVUotAAYCgUqpaOAlwAagtZ4BTAECgI+UUgC5+V0wuUqpJ4EVgBWYrbU+UC1/hagdGnVAhd/G0/uXktptvNnRCCHyqdq4BmivXr309u3bzQ5DXImMv+Cjq6GBF3mPrMXu4obNKvflCVHdlFI7tNa9HO0rs0UvRIW4+xmFzz6PYsm/H+bVvPtJycylma87k4aFEdWjxIlXQohqIoleVL02gzjWZhzuRw/xo3qcZg0SiE0P5N2ldwOPS7IXoobJd2pRLb447ct1ll2EWBKwKAixJDBVzWT38plmhyZEvSOJXlSLh7Pn46Gyi2zzUNk8nD3fpIiEqL8k0Ytq0cySWKHtQojqI4leVItM9yaOt7s1quFIhBCS6EW18Bg+lVyrW5FtGsjOymbuzzJ1VoiaJLNuRPXoeqfxP9cvUyE5GnxC0F3vZtf+k7z8yx9oj1M80C/U7CiFqBck0Yvq0/VO4yefBeg/0M4NX+5i7g+/EppoZeCIcaaFJ0R9IV03okbZrBamj+7Bm/7fc+2OZ9jzzetmhySE05NEL2qcq4uF7k98zj6vfnTb/wb87wWw55kdlhBOSxK9MIWbR0O6PfsdRDwGWz4mbf4YyE43OywhnJL00QvzWKww/E12pvig9y8l9Wg8A8Jbmh2VEE5HEr0wXZtbJnHvH1dzeOFB5t1jp29jOwS0MTssIZyGdN0I0/m425j30NW0DvQkceHj5HxyHZzZbHZYQjgNSfSiVvDzdGX+wxEsbHgfMVnu6Hkj4MBSs8MSwilIohe1RqBXA95+9FaO3bIE1awHfD0ONkyHWrg4jhB1iSR6Uas09nbj+l6d4L5viW8xnJwNHxirVgkhrpgMxopaKcfiyqiER/DIjGN6qo22bnmQmwWuHmaHJkSdIy16USvZrBZmPxBBnCWIez7dQvJ3k2HODZDyp9mhCVHnSKIXtVbrIC++fCSCXLvm1f0B2OOPwqwhEHfY7NCEqFMk0YtarX3jhnz+UB9W5nbni44fQ24mzB4Kv/9mdmhC1BlK18IZDb169dLbt0vNcnHJmcR0QvzcsSSfgS9GQco5eGYvuPuZHZoQtYJSaofWupejfdKiF3VCiwAPLBbFGXsQT7q/QfKI2ZLkhSgnSfSiTolNzuDnU1mMXuVGcnoO7P4Svnsa8nLMDk2IWksSvahTIlsHMPO+XhyPS+W+2VvISjgFO+fBl3dBVorZ4QlRK0miF3XOgPZBfDSmJwdiLzDm2CCybnwPTq6BOcPhQqzZ4QlR60iiF3XSkE6NmT66BxrIDB8DYxbB+VPG9MuMJLPDE6JWkTtjRZ11Y5em3NC5CRaLIrPlICz3/4jr6XXg7mt2aELUKtKiF3WaxaKw2zWPfLadx1flkBPxhLHj7DZjoFYIIYle1H0Wi2Jop8asOvQnzyzcTW6eHbbMgGUTYPXrUv1S1HvSdSOcwr19W5GVa+e15YewWRVv3/4xVpcGsPYNOLkWLpyF5BjwCYHBU6DrnWaHLESNkUQvnMbD17QmK9fOtBVHCPRqwIsjP4SsVDj07aWDks/C908bjyXZi3pCEr1wKk8MaovVohgU1giUgtidxQ/KyYBfpkqiF/WGJHrhdB4bYCwsrrWG5GiUo4OSo2s0JiHMJIOxwmmtOhRHjD2ghL0avp8IqfE1GpMQZigz0SulZiul4pRS+0vY30EptUkplaWUeu6yfb8rpfYppXYrpaQcpahRgzs0Yqnfg6Rr1yLbM7QrfwT1h13z4f2esOkjkyIUomaUp0U/F7ihlP3ngaeBt0rYP0hr3b2k8plCVBeLRbEgK5IXch4m2h6IXSui7YE8n/Mwt6c8CxM2QYu+8Ncps0MVolqV2UevtV6nlGpVyv44IE4pdVMVxiVElTiXlMl39Oe77P5FtqukDAhqb5ROKKh8eXojrHkDhv0LmoSbEK0Q1aO6++g1sFIptUMpNb60A5VS45VS25VS2+Pjpd9UVI1mvu4Otwc1bHDpidVm/E6Ngz/2wifXwPfPQFpCDUQoRPWr7kTfT2vdExgOPKGUurakA7XWM7XWvbTWvYKCgqo5LDly0oEAABQSSURBVFFfTBoWhrvNWmSbq4uFuJQsXly2j4zsvEs7OkfBUzuhz3jY+RlM7wHb/lvDEQtR9ao10WutY/N/xwFLgT7VeT0hLhfVI5jXb+tCsK87Cgj2dedfUeGMv7Y18zef4eb317M/JvnSCzz8Yfib8PgmaB5hzLkHo4yClFIQdVS1zaNXSnkCFq11Sv7jocDU6rqeECWJ6hFMVI/gYtuvbRfEs1/v5taPNjB5eEce7B96aWdQGIz9Bux24/mehbB3odF/37hzDUUuRNUoz/TKBcAmIEwpFa2Uekgp9ZhS6rH8/U2UUtHA34EX84/xBhoDvyml9gBbgeVa65+q708RomL6twvkp4nXMrhDY2wuJfxTsBRs1xC7G2b0hx/+Jv33ok5RuhZ+He3Vq5fevl2m3YuaUfBvQCnF8r3nALipa9PiB6afN2blbJsFrl5GF0/30TUZqhAlUkrtKGkau9wZK+o9pRRKKbTWLNx2hie+3Mmkr/eQmpVb9EAPf7jx3/n9972hQUNjuz1P+u9FrSaJXoh8Silmj+vNU9e1ZfHOaG6avp5dZ/4qfmBQGIxdDB3ybx1ZNw0+vxX+PFizAQtRTpLohSjEZrXw7NAwFo7vS26e5o4ZmzgZn+r4YJVfLs2rEcTughn9YPmzkJZYcwELUQ7SRy9ECS5k5vC/fee4q3cLADKy83B3tTo+OP08rHndmHffwAtGvA+dRtZgtKK+kz56Ia6At5vtYpI/EJtM/zd/ZdmuGMcHe/jDjdNgwkYI6QO+LY3tuVnSfy9MJ/XohSgHbzcboYGePPPVblYfiePVqHC83WzFD2zUwZh/X+D7ZyD1D2P+/R/7jAVPkqNlSUNRoyTRC1EOzf09WDg+ko/WnOC9X46x/fe/ePfu7vRu5V/6C5t2gzXL4aO+YLGCPX8mjyxpKGqQdN0IUU4uVgtPD27H14/1xcWqWH04ruwXRT4GT+0CV89LSb5AwZKGQlQzadELUUE9W/ix/OlrcLUa7aSdZ/7Cz8OV0EBPxy/wDIDsNMf7ZElDUQOkRS/EFfBq4IKriwWtNf+3ZB83TV/Pom1nKXEWm09ICWfSMPdmOLzcuPFKiGogiV6ISlBKMeeB3nQL8eUfi/fy+Bc7+Sstu/iBg6eA7bLa+C7u0Pk2OH8KFt5jlEXe/WXNBC7qFUn0QlRSUx93vng4gsnDO7Dq0J/c8N46YpIyih7U9U64ZTr4NAeU8XvEdBg1BybugVHzwLsZpOUvupObBQnHa/xvEc5JbpgSogrtj0lm0fazvDKiM6rgztmKsNuNipl7FsLSR6Ht9caAbpvBl+7EFcIBuWFKiBoSHuzD1JHhKKWIScpg9MzNHI9LKf8JCsoit7kOBk6Gc3tg/u3wYR+jamZebumvF8IBadELUU22njrPY/N3kJaVy4s3d8LL1cpbK48Sm5RBM193Jg0Lc7ggShG5WXBgKWz+2FjEfMIGo2WfeQHcvGvmDxF1Qmktekn0QlSjuJRMnvt6L+uOxmNRYC/0z83dZuX127qUnezBKKOQ8ZdRaiHzArwbDq2ugcgJ0LKfdOsI6boRwiyNGroxd1xvfNxdiiR5gIycPKatOFK+EyllJHkAnQe9HoTTG2DuTTDjGtj5OeRkVm3wwmlIoheimlksigsZjvvWYy+fnVMe7n4w5GX4+yFjJo/Og++ehISjxv5a+C1dmEvujBWiBjTzdS8+5RJwd7WSmJpFgFeDip/U5g5X3Q897zPq4Tftamz/7kmjdR85AUIcfpMX9Yy06IWoAZOGheFuK1rL3mpRZGTnMfCtNcxaf5LsXPuVnVwpCO556blHIBxbCbMGw6eDYd83xkCuqLck0QtRA6J6BPP6bV0I9nVHAcG+7rw9qhs///1armrpx2vLD7Fo+9mqudj1r8DfD8LwacYA7uKHYO2bl/bvXQT/CYeXfY3fexdVzXVFrSWzboSoBdYfiyciNABXFwsbjicQ6NWAsCYNK39iux2Or4JGHcG3Oax6BTa8Z/TrF7C5G339Ui65TpNZN0LUcte0C7pYJO3VHw4y/L11vLhsH+cd1c2pCIsF2g81kjzAjjlFkzxIueR6QBK9ELWIUooFj0QyNrIlC7aeZeC01fz3t1NX3n9/uYwkx9sLyiUf+gFidhrfBITTkFk3QtQyfp6uTB0ZztjIlrz6w0Fe/eEgrQI8GNyxceVP7hNirG7laLvW8MMzRmE1d39oPdAoxdB2sFFwTdRZ0qIXopZq37ghnz3Yh0WP9uW6Do0A+H5PLMf+rEDtnMs5Kpdscze2K2Usbn7bp9B+mHFD1ndPwsb3jePycuHoypIXURG1lrTohajFlFL0CTXuiM3OtfPP5YeIT81ibEQLnhnSHj9P14qdsGDAtaRFyr0aGY+73mm08OMOXvpgiNkBX44Ciw1aREKbQUaLv0m3S8XYRK0ks26EqEPOp2Xzn5+P8sWW0zR0s/HMkHaMjWyJzVoDiTYnE85uhhO/Gj9/7DO23/89hF4LF2JB20tZTUtUJylqJoSTOfJHCq/+cJDfjifww1P9CQ/2qfkgUuPg5BroNBJcGsDPL8GGdyEw7FJrv2U/aOBV87HVQ5LohXBCWmsOxF64mOTnbjhF/3aBtG1UBfPvr0TCcTj6k9HaP70BcjONu3SfO2Z07VyIBa8ml7p59i4quQtJVJgkeiGcXFJ6NgOmrSE1K5d7I1vyzJB2+HpUsP++KuVkwplNkHIOut9jbPugjzGjp80gcPWCvV8ZHwYF5MatSpFEL0Q9kJiaxds/H2Xh1jN4u9v425D2jIlogUtN9N+XRWvY9/Wl/v3UPx0f59kIHlsPXo2lxn4FSaIXoh45dO4Cr/5wkF1nklj93ECa+LiZHVJRWsMrfkApucfmCf6tYcA/oNMIyEqBc3shoI18CJSgtEQv0yuFcDIdm3rzxcMR/J6YThMfN7TWvL3yKLf2DKZNUC0YGFWq5Bu3PINgwPNw/iQkngBXD2P7uT3GIitw6UMgoDVc8yw07WZ8EGSnyYdACSTRC+GElFKEBnoCcOZ8OnM3/s6MtSe4r28r2jby5MPVJyq2dm1VGzwFvn/aqLNTwOYOw/7luI++cTiMXQznTxkfAOdPwB/7Ly2WfvhHWDre6Pv3DzU+CPzbQMRj0LCxUabZ4lL8Q6CeDAhL140Q9UB8Shbv/HyEBVuLt6IrtHZtVarKJJt4Ao7/YnwAFHwbSDoNz+wzyjesfxvWv5P/IdDG+CBIT4R9i4p/2NTRAeFK9dErpWYDNwNxWutwB/s7AHOAnsD/p7V+q9C+G4D3ACswS2v9RnkClkQvRPXo/c9VxKdkFdse7OvOhheuMyGiapSXCxar0Yo/uQaO/C//28BJ40PA7nh5R6yuxsLrXo3h1o+NbYeXG9NDG3iDmze4+Rj1gBp1MPZrXbkuoyr40KtsH/1c4APgsxL2nweeBqIuu6gV+BC4HogGtimlvtNaHyxn3EKIKpbgIMkDxCRl8OO+cwzp2BhXl1owS6cqWAult9YDjZ8CeTnwahAOB4Tzso0FW3LSL23bMQ+OrSh6nF8oTNxtPP48CmJ2GR8CDfI/CJqEw43TjP3b/muMI1zc7wveTaFxZyPJf/c05OZ/s0g+a3RrQZV9sygz0Wut1ymlWpWyPw6IU0rddNmuPsBxrfVJAKXUQmAkIIleCJOUtHatVSke/2IngV6u3HFVc+7t25JgX3cHZ3ASVlsplTybw/jVRbfd9TlkXoCsC5CZbPwUbsF3GglBHYoek13og2LbLKNuUGGtB8F9y4yWfO5l/00K1gioqURfCcFA4XcxGogo6WCl1HhgPECLFi2qMSwh6q9Jw8KYvGQfGTmXFh9xt1n5Z1Q4fl6uLNhyhk/Xn6Rf2wCCfd25kJmDm4vVeVr5hZU0IDx4SvFjXRqAV5Dx40ivB0u/1oSNxqygrAuXPgxc8qe9FqwFcLmStl+B6kz0jjqsShwQ0FrPBGaC0UdfXUEJUZ8VDLhOW3HE4aybQWGN+PNCJkFeDQD44NfjLN4RzR1XhXB3nxYXZ/I4hbIqeVYlpYyaPw28itf2L22NgCpSnYk+Gmhe6HkIEFuN1xNClENUj+BSZ9g09r50g9XAsCBOJ6Yx67dTfLLuJH1bB3Bf35YM79K0JkKtfgUlmc1UkW8WV6g6E/02oJ1SKhSIAe4G7qnG6wkhqtjVbQK5uk0gcRcy+XpHNAu3neHng39eTPRnz6fT3N/D5CjruBr4ZlGe6ZULgIFAIPAn8BJgA9Baz1BKNQG2A96AHUgFOmmtLyilbgTexZheOVtr/c/yBCXTK4Wonex2TWp2Lt5uNg7EJnPT9N+ICPXnnogWDOvcBDeb1ewQ6y2pdSOEqHLn07JZuO0MC7ee5cz5dHw9bNzeM4QnB7Wt+MpXotJKS/ROOJQuhKgJ/p6uPD6wLWueG8j8hyLo1yaQxTujL87QORmfSmah2T3CPFLrRghRKRaLon+7QPq3CyQjOw93Vytaax7/YifnkjO5rWcwo/u0oH1jkxZEEZLohRBVx931Uh/9lFs6sWDrWeZvPs2cDb/Tq6UfTw1ux4D2xlz0ZbtiSpzmKaqWJHohRJVTSl2csZOY2oklO2NYsPUMf6VlA/DlltO88v1BsnLtgFGCYfISY7FxSfZVTwZjhRA1QmuNXYPVouj68gouZBYvKuaUxdVqiAzGCiFMp5TCajFumE9xkOQBYvPr8Jw9n056dgnVJUWFSdeNEKLGlVRcrVl+IbXnvt7DjtN/0TXEhz6hAUS09qdXSz8autlqOlSnIC16IUSNmzQsDPfLbq5yt1mZNCwMgKeua8cj17YGYNb6kzwwZxtPfrnr4rEbTySQnJ5TcwHXcdKiF0LUuLKKqxVM1wRIz85l5+kkbFaj2yc5PYcxs7YA0KGJNxGh/kS29ieydQC+HnKjliMyGCuEqFNy8uzsOP0XW06eZ8upRHae+YvMHDtTR3bmvr6tSEjNYtOJRCJa+9OooVvZJ3QSlV1hSgghag2b1UJk6wAiWwcA7cjOtbMvJulicbX1x+L521d7AGgd6ElEa3/6hPozpGPjYn389WUuv7TohRBOJTfPzoHYC2w5lciWk+fZ+vt5UjJz2fjCdTTzdWfD8QRikjJIycjhrZVHyMixX3ytaQulVwFp0Qsh6g0Xq4VuzX3p1tyX8de2Ic+uORaXcnFGz5KdMSze6Xj1poycPKatOFwnE31ppEUvhKhX7HbNsbhUhr27rsRjWgV40Nzfg5YBHrT096RzM2+ubhtYg1FWnLTohRAin8WiCGvSkOAS5vJ7u7nQOdiHM4np7I0+R3JGDoM7NLqY6G95/zdsVkXLAE/jw8Dfgy4hPrW6aJskeiFEvVTSQulTR4YX6bpJTs8hPce4S1drTXiwD78npLH11HmW7Y5Baxgb2YLXorqQm2fnlg82EOzrbnwbyP9m0LmpN428S54BVN2DwpLohRD1Ullz+Qv4eNjwMRbVQynF67d1ubgvKzePmL8ysFmNe0/TsvMI9nXn7Pl0fjseT2b+QO+kYWE8MagtcRcymbhwNy38PWgR4EELfw9OJaTy0ZoTF4+tjgJv0kcvhBDVQGtNfEoWZ86n09jbjeb+HpyIT+Uf3+zldGI6CalZpb6+ogXepI9eCCFqmFKKRt5uRbps2gR5sXjC1QCkZeVy5nw6w99b7/D1sQ7GD66U1LoRQggTeDZwoWNTb4Lzp31erlkJ26+EJHohhDBRWQXeqoJ03QghhInKOyhcGZLohRDCZFE9gqv1blzpuhFCCCcniV4IIZycJHohhHBykuiFEMLJSaIXQggnVytLICil4oHTV/jyQCChCsOpy+S9KErej6Lk/bjEGd6LllrrIEc7amWirwyl1PaS6j3UN/JeFCXvR1Hyflzi7O+FdN0IIYSTk0QvhBBOzhkT/UyzA6hF5L0oSt6PouT9uMSp3wun66MXQghRlDO26IUQQhQiiV4IIZyc0yR6pdQNSqkjSqnjSqkXzI7HTEqp5kqp1UqpQ0qpA0qpiWbHZDallFUptUsp9YPZsZhNKeWrlPpGKXU4//+RvmbHZCal1N/y/53sV0otUEqVvIp3HeUUiV4pZQU+BIYDnYDRSqlO5kZlqlzgWa11RyASeKKevx8AE4FDZgdRS7wH/KS17gB0ox6/L0qpYOBpoJfWOhywAnebG1XVc4pED/QBjmutT2qts4GFwEiTYzKN1vqc1npn/uMUjH/I1VfsupZTSoUANwGzzI7FbEopb+Ba4L8AWutsrXWSuVGZzgVwV0q5AB5ArMnxVDlnSfTBwNlCz6Opx4mtMKVUK6AHsMXcSEz1LvAPwG52ILVAayAemJPflTVLKeVpdlBm0VrHAG8BZ4BzQLLWeqW5UVU9Z0n0ysG2ej9vVCnlBSwGntFaXzA7HjMopW4G4rTWO8yOpZZwAXoCH2utewBpQL0d01JK+WF8+w8FmgGeSqmx5kZV9Zwl0UcDzQs9D8EJv35VhFLKhpHkv9BaLzE7HhP1A0YopX7H6NK7Tik139yQTBUNRGutC77hfYOR+OurIcAprXW81joHWAJcbXJMVc5ZEv02oJ1SKlQp5YoxmPKdyTGZRimlMPpgD2mt3zE7HjNprSdrrUO01q0w/r/4VWvtdC228tJa/wGcVUqF5W8aDBw0MSSznQEilVIe+f9uBuOEg9NOsTi41jpXKfUksAJj1Hy21vqAyWGZqR9wL7BPKbU7f9v/aa1/NDEmUXs8BXyR3yg6CTxgcjym0VpvUUp9A+zEmK22CycshyAlEIQQwsk5S9eNEEKIEkiiF0IIJyeJXgghnJwkeiGEcHKS6IUQwslJohdCCCcniV4IIZzc/wNp21ygXbuQvAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "f = RecSys_FM(train,y_train,num_components=10,k=10)\n",
    "f.fit(y_val,n_epochs=10,learning_rate=0.05,lmbda=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-09T11:28:02.920421Z",
     "start_time": "2021-04-09T11:28:00.434545Z"
    }
   },
   "outputs": [],
   "source": [
    "y_pred = f.predict(val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "\n",
    "### Basic RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-09T11:28:02.936377Z",
     "start_time": "2021-04-09T11:28:02.921409Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for Collaborative Recomender: 1.1180573813554475\n"
     ]
    }
   ],
   "source": [
    "print('RMSE for Collaborative Recomender: %s' % compute_rmse(y_val,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NDCG \n",
    "\n",
    "I also implemented a Normalized Discount Cumulative Gain evaluation function (above the notebook). My initial goal was to use it alongside my SGD as loss function, but I could not made it work due to lack of time (specially for others deliveries we had this week) and maybe lack of knowledge. \n",
    "\n",
    "What I did was use it as it is, after the training of my recommender system. I also tried to print it on each epoch, but its value does not change much, of course, specially if you \"pick\" a few movies (because you're sorting the k=10 movies or so).\n",
    "\n",
    "\\begin{align}\n",
    "DCG_k = \\sum_{i=1}^k \\frac{2^{rel_i} - 1}{\\log_2{\\left(i+1\\right)}}\n",
    "\\end{align}\n",
    "\n",
    "So, I use this evaluation method by first computing the DCG of the best ranking score and then divide it by the ideal DCG, getting a score between 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-09T11:32:06.623507Z",
     "start_time": "2021-04-09T11:32:06.607505Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NDCG of Validation: 0.7830070575713997\n"
     ]
    }
   ],
   "source": [
    "ndcgTrain = ndcg(y_pred,y_val,10)\n",
    "possible = ndcg(y_val,y_val,10)\n",
    "print('NDCG of Validation:',ndcgTrain/possible)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I did several parameter hypertunning in order to find out the optimal combination, evaluating each training with the methods just described and the Kaggle competition result. Below are a few of the total 21 submissions done:\n",
    "\n",
    "| K  | Epochs | Learning Rate | Lambda | Train RMSE | Val. RMSE | Time (hours) | Dataset size | Kaggle Score |\n",
    "|----|--------|---------------|--------|------------|-----------|--------------|--------------|--------------|\n",
    "| 10 | 60     | 0.01          | 0.03   | 0.46       | 1.06      | ~5           | 101k         | 0.69989      |\n",
    "| 10 | 60     | 0.01          | 0.01   | 0.41       | 1.06      | ~5           | 101k         | 0.69071      |\n",
    "| 5  | 66     | 0.01          | 0.03   | 0.42       | 1.08      | ~4           | 101k         | 0.68763      |\n",
    "| 10 | 80     | 0.01          | 0.03   | -          | -         | ~7           | 201k         | 0.67006      |\n",
    "| 10 | 100    | 0.01          | 0.03   | -          | 1.06      | ~7           | 101k         | 0.66658      |\n",
    "| 10 | 70     | 0.001         | 0.003  | 0.75       | 0.98      | ~10          | All          | 0.66382      |\n",
    "| 10 | 60     | 0.001         | 0.003  | 0.77       | 1.18      | ~10          | All          | 0.55420      |\n",
    "\n",
    "I got 0.69 just after finishing the code so I went berserk trying to at least get 0.7 but I could not make it. I tried to change the dataset size, increase and decrese the learning rate and lambda and also to increase or decrease the iterations performed, resulting in minor changes of the Kaggle score.\n",
    "\n",
    "## Submission\n",
    "\n",
    "Predict with my test set and sort!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-09T11:16:37.615488Z",
     "start_time": "2021-04-09T11:13:33.306732Z"
    }
   },
   "outputs": [],
   "source": [
    "testPred=f.predict(test)\n",
    "df_test[\"estimated\"] = testPred\n",
    "df_test.sort_values(by='estimated',ascending=False)[['user_id','movie_id']].to_csv('SubmissionBlaiRas.csv',index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
